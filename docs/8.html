
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Chapter 8.用于自然语言处理的高级 Sequence · NLP with PyTorch 中文文档</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="ApacheCN">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-alerts/style.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-auto-scroll-table/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-advanced-emoji/emoji-website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="9.html" />
    
    
    <link rel="prev" href="7.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"apachecn","repo":"nlp-pytorch-zh","type":"star","count":true,"size":"small"}]};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    入门须知
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="1.html">
            
                <a href="1.html">
            
                    
                    Chapter 1.基础介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="2.html">
            
                <a href="2.html">
            
                    
                    Chapter 2.传统NLP快速回顾
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="3.html">
            
                <a href="3.html">
            
                    
                    Chapter 3.神经网络基础组件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="4.html">
            
                <a href="4.html">
            
                    
                    Chapter 4.自然语言处理 Feed-Forward Networks
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="5.html">
            
                <a href="5.html">
            
                    
                    Chapter 5.Embedding Words and Types
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="6.html">
            
                <a href="6.html">
            
                    
                    Chapter 6.自然语言处理 Sequence Modeling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="7.html">
            
                <a href="7.html">
            
                    
                    Chapter 7.自然语言处理的中间 Sequence Modeling
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.9" data-path="8.html">
            
                <a href="8.html">
            
                    
                    Chapter 8.用于自然语言处理的高级 Sequence
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="9.html">
            
                <a href="9.html">
            
                    
                    Chapter 9.经典, 前沿和后续步骤
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Chapter 8.用于自然语言处理的高级 Sequence</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="chapter-8-advanced-sequence-modeling-for-natural-language-processing">Chapter 8. Advanced Sequence Modeling for Natural Language Processing</h1>
<blockquote>
<p>&#x672C;&#x6587;&#x6807;&#x9898;:<a href="https://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch%EF%BC%88%E5%85%AB%EF%BC%89/" target="_blank">Natural-Language-Processing-with-PyTorch&#xFF08;&#x516B;&#xFF09;</a></p>
<p>&#x6587;&#x7AE0;&#x4F5C;&#x8005;:<a href="https://yifdu.github.io/" title="&#x8BBF;&#x95EE; Yif Du &#x7684;&#x4E2A;&#x4EBA;&#x535A;&#x5BA2;" target="_blank">Yif Du</a></p>
<p>&#x53D1;&#x5E03;&#x65F6;&#x95F4;:2018&#x5E74;12&#x6708;28&#x65E5; - 09:12</p>
<p>&#x6700;&#x540E;&#x66F4;&#x65B0;:2018&#x5E74;12&#x6708;28&#x65E5; - 11:12</p>
<p>&#x539F;&#x59CB;&#x94FE;&#x63A5;:<a href="https://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch%EF%BC%88%E5%85%AB%EF%BC%89/" target="_blank">http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch&#xFF08;&#x516B;&#xFF09;/</a></p>
<p>&#x8BB8;&#x53EF;&#x534F;&#x8BAE;:  <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">&#x7F72;&#x540D;-&#x975E;&#x5546;&#x4E1A;&#x6027;&#x4F7F;&#x7528;-&#x7981;&#x6B62;&#x6F14;&#x7ECE; 4.0 &#x56FD;&#x9645;</a>  &#x8F6C;&#x8F7D;&#x8BF7;&#x4FDD;&#x7559;&#x539F;&#x6587;&#x94FE;&#x63A5;&#x53CA;&#x4F5C;&#x8005;&#x3002;</p>
</blockquote>
<p>&#x5728;&#x672C;&#x7AE0;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x4EE5;&#x7B2C;&#x516D;&#x7AE0;&#x548C;&#x7B2C;&#x4E03;&#x7AE0;&#x8BA8;&#x8BBA;&#x7684;&#x5E8F;&#x5217;&#x5EFA;&#x6A21;&#x6982;&#x5FF5;&#x4E3A;&#x57FA;&#x7840;&#xFF0C;&#x5C06;&#x5B83;&#x4EEC;&#x6269;&#x5C55;&#x5230;&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;&#x5EFA;&#x6A21;&#x7684;&#x9886;&#x57DF;&#xFF0C;&#x5176;&#x4E2D;&#x6A21;&#x578B;&#x4EE5;&#x4E00;&#x4E2A;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x5E76;&#x4EA7;&#x751F;&#x53E6;&#x4E00;&#x4E2A;&#x53EF;&#x80FD;&#x4E0D;&#x540C;&#x957F;&#x5EA6;&#x7684;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x8F93;&#x51FA;&#x3002;&#x5E8F;&#x5217;&#x5BF9;&#x5E8F;&#x5217;&#x95EE;&#x9898;&#x7684;&#x4F8B;&#x5B50;&#x968F;&#x5904;&#x53EF;&#x89C1;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x7ED9;&#x5B9A;&#x4E00;&#x5C01;&#x7535;&#x5B50;&#x90AE;&#x4EF6;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x80FD;&#x5E0C;&#x671B;&#x9884;&#x6D4B;&#x54CD;&#x5E94;&#x3002;&#x7ED9;&#x51FA;&#x4E00;&#x4E2A;&#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#xFF0C;&#x9884;&#x6D4B;&#x5B83;&#x7684;&#x82F1;&#x8BED;&#x7FFB;&#x8BD1;&#x3002;&#x6216;&#x8005;&#xFF0C;&#x7ED9;&#x5B9A;&#x4E00;&#x7BC7;&#x6587;&#x7AE0;&#xFF0C;&#x5199;&#x4E00;&#x7BC7;&#x6458;&#x8981;&#x3002;&#x6211;&#x4EEC;&#x8FD8;&#x8BA8;&#x8BBA;&#x4E86;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#x7684;&#x7ED3;&#x6784;&#x53D8;&#x4F53;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x53CC;&#x5411;&#x6A21;&#x578B;&#x3002;&#x4E3A;&#x4E86;&#x6700;&#x5927;&#x9650;&#x5EA6;&#x5730;&#x5229;&#x7528;&#x5E8F;&#x5217;&#x8868;&#x793A;&#xFF0C;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x4E86;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x5E76;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x4E86;&#x6DF1;&#x5165;&#x8BA8;&#x8BBA;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x672C;&#x7AE0;&#x4EE5;&#x5B9E;&#x73B0;&#x672C;&#x7AE0;&#x63CF;&#x8FF0;&#x7684;&#x6982;&#x5FF5;&#x7684;&#x795E;&#x7ECF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x7684;&#x8BE6;&#x7EC6;&#x6F14;&#x7EC3;&#x7ED3;&#x675F;&#x3002;</p>
<h2 id="sequence-to-sequence-models-encoder&#x2013;decoder-models-and-conditioned-generation">Sequence-to-Sequence Models, Encoder&#x2013;Decoder Models, and Conditioned Generation</h2>
<p>&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;(S2S)&#x6A21;&#x578B;&#x662F;&#x4E00;&#x79CD;&#x79F0;&#x4E3A;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x7684;&#x4E00;&#x822C;&#x6A21;&#x578B;&#x5BB6;&#x65CF;&#x7684;&#x7279;&#x6B8A;&#x60C5;&#x51B5;&#x3002;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x662F;&#x4E24;&#x4E2A;&#x6A21;&#x578B;(&#x56FE;8-1)&#x7684;&#x7EC4;&#x5408;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x201C;&#x7F16;&#x7801;&#x5668;&#x201D;&#x6A21;&#x578B;&#xFF0C;&#x53E6;&#x4E00;&#x4E2A;&#x662F;&#x201C;&#x89E3;&#x7801;&#x5668;&#x201D;&#x6A21;&#x578B;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;&#x6A21;&#x578B;&#x901A;&#x5E38;&#x662F;&#x8054;&#x5408;&#x8BAD;&#x7EC3;&#x7684;&#x3002;&#x7F16;&#x7801;&#x5668;&#x6A21;&#x578B;&#x9700;&#x8981;&#x8F93;&#x5165;&#x5E76;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x7F16;&#x7801;&#x6216;&#x8868;&#x793A;&#x3D5;&#x7684;&#x8F93;&#x5165;,&#x901A;&#x5E38;&#x4E00;&#x4E2A;&#x5411;&#x91CF;&#x3002;&#x7F16;&#x7801;&#x5668;&#x7684;&#x76EE;&#x6807;&#x662F;&#x6355;&#x83B7;&#x4E0E;&#x5F53;&#x524D;&#x4EFB;&#x52A1;&#x76F8;&#x5173;&#x7684;&#x8F93;&#x5165;&#x7684;&#x91CD;&#x8981;&#x5C5E;&#x6027;&#x3002;&#x89E3;&#x7801;&#x5668;&#x7684;&#x76EE;&#x6807;&#x662F;&#x83B7;&#x53D6;&#x7F16;&#x7801;&#x8F93;&#x5165;&#x5E76;&#x4EA7;&#x751F;&#x6240;&#x9700;&#x7684;&#x8F93;&#x51FA;&#x3002;&#x901A;&#x8FC7;&#x5BF9;&#x7F16;&#x7801;&#x5668;&#x548C;&#x89E3;&#x7801;&#x5668;&#x7684;&#x7406;&#x89E3;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;S2S&#x6A21;&#x578B;&#x5B9A;&#x4E49;&#x4E3A;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#xFF0C;&#x5176;&#x4E2D;&#x7F16;&#x7801;&#x5668;&#x548C;&#x89E3;&#x7801;&#x5668;&#x662F;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#xFF0C;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x90FD;&#x662F;&#x5E8F;&#x5217;&#xFF0C;&#x53EF;&#x80FD;&#x957F;&#x5EA6;&#x4E0D;&#x540C;&#x3002; <img src="img/e35a261d985c5ea7ba83bde48d98929d.jpg" alt="S2S" title="&#x56FE;8-1&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x662F;&#x7531;&#x4E24;&#x4E2A;&#x8054;&#x5408;&#x8BAD;&#x7EC3;&#x7684;&#x6A21;&#x578B;&#x7EC4;&#x6210;&#x7684;&#x3002;&#x7F16;&#x7801;&#x5668;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x4EE3;&#x8868;&#x6216;&#x7F16;&#x7801;&#x8F93;&#x5165;&#x3D5;&#x7684;&#x89E3;&#x7801;&#x5668;&#x7528;&#x6765;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;&#x3002;"> &#x4E00;&#x79CD;&#x67E5;&#x770B;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x7684;&#x65B9;&#x6CD5;&#x662F;&#x5C06;&#x5176;&#x4F5C;&#x4E3A;&#x79F0;&#x4E3A;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x6A21;&#x578B;&#x7684;&#x6A21;&#x578B;&#x7684;&#x7279;&#x6B8A;&#x60C5;&#x51B5;&#x3002;&#x5728;conditioned-generation&#x4E2D;,&#x66FF;&#x4EE3;&#x8F93;&#x5165;&#x8868;&#x793A;&#x3D5;,&#x4E00;&#x822C;&#x6761;&#x4EF6;&#x4E0A;&#x4E0B;&#x6587;c&#x5F71;&#x54CD;&#x8BD1;&#x7801;&#x5668;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;&#x3002;&#x5F53;&#x6761;&#x4EF6;&#x4E0A;&#x4E0B;&#x6587;c&#x6765;&#x81EA;&#x7F16;&#x7801;&#x5668;&#x6A21;&#x578B;&#x65F6;&#xFF0C;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x4E0E;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x76F8;&#x540C;&#x3002;&#x5E76;&#x975E;&#x6240;&#x6709;&#x7684;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x6A21;&#x578B;&#x90FD;&#x662F;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#xFF0C;&#x56E0;&#x4E3A;&#x6761;&#x4EF6;&#x4E0A;&#x4E0B;&#x6587;&#x53EF;&#x80FD;&#x6765;&#x81EA;&#x7ED3;&#x6784;&#x5316;&#x6E90;&#x3002;&#x4EE5;&#x5929;&#x6C14;&#x62A5;&#x544A;&#x751F;&#x6210;&#x5668;&#x4E3A;&#x4F8B;&#x3002;&#x6E29;&#x5EA6;&#x3001;&#x6E7F;&#x5EA6;&#x3001;&#x98CE;&#x901F;&#x548C;&#x98CE;&#x5411;&#x7684;&#x503C;&#x53EF;&#x4EE5;&#x201C;&#x8C03;&#x8282;&#x201D;&#x89E3;&#x7801;&#x5668;&#xFF0C;&#x751F;&#x6210;&#x6587;&#x672C;&#x5929;&#x6C14;&#x62A5;&#x544A;&#x3002;&#x5728;&#x201C;&#x6A21;&#x578B;2:&#x6761;&#x4EF6;&#x6027;&#x59D3;&#x6C0F;&#x751F;&#x6210;&#x6A21;&#x578B;&#x201D;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x770B;&#x5230;&#x4E86;&#x4E00;&#x4E2A;&#x57FA;&#x4E8E;&#x56FD;&#x7C4D;&#x6761;&#x4EF6;&#x6027;&#x59D3;&#x6C0F;&#x751F;&#x6210;&#x7684;&#x4F8B;&#x5B50;&#x3002;&#x56FE;8-2&#x5C55;&#x793A;&#x4E86;&#x4E00;&#x4E9B;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x6A21;&#x578B;&#x7684;&#x5B9E;&#x9645;&#x793A;&#x4F8B;&#x3002;</p>
<p><img src="img/e0efc32c40cec36d36b5cb2245b6f4b4.jpg" alt="example" title="&#x56FE;8 - 2&#x3002;&#x7528;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x89E3;&#x51B3;&#x7684;&#x4EFB;&#x52A1;&#x793A;&#x4F8B;&#x3002;&#xFF08;&#x4E00;&#xFF09;&#x673A;&#x5668;&#x7FFB;&#x8BD1;:&#x8F93;&#x5165;A&#x4E3A;&#x6CD5;&#x8BED;&#x53E5;&#xFF0C;&#x8F93;&#x51FA;B&#x4E3A;&#x82F1;&#x8BED;&#x53E5;&#x3002;&#xFF08;&#x4E8C;&#xFF09;&#x90AE;&#x4EF6;&#x56DE;&#x590D;&#x5EFA;&#x8BAE;:&#x8F93;&#x5165;A&#x4E3A;&#x90AE;&#x4EF6;&#x6587;&#x672C;;&#x8F93;&#x51FA;B&#x662F;&#x8BB8;&#x591A;&#x53EF;&#x80FD;&#x7684;&#x7B54;&#x590D;&#x4E4B;&#x4E00;&#x3002;&#x5728;&#xFF08;III&#xFF09;&#x4E2D;&#xFF0C;&#x7ED9;&#x51FA;&#x4E86;&#x4E00;&#x4E2A;&#x66F4;&#x590D;&#x6742;&#x7684;&#x4F8B;&#x5B50;&#x3002;&#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x804A;&#x5929;&#x673A;&#x5668;&#x4EBA;&#x6B63;&#x5728;&#x56DE;&#x7B54;&#x4EE5;a&#x4E3A;&#x6807;&#x8BB0;&#x7684;&#x5173;&#x4E8E;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#xFF08;a &apos;&#xFF09;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x5B83;&#x5C06;&#x54CD;&#x5E94;B&#x7684;&#x751F;&#x6210;&#x6761;&#x4EF6;&#x8BBE;&#x7F6E;&#x4E3A;a&#x548C;a&#x7684;&#x7F16;&#x7801;&#x3002;&#x6240;&#x6709;&#x8FD9;&#x4E9B;&#x4EFB;&#x52A1;&#x4E5F;&#x53EF;&#x4EE5;&#x770B;&#x4F5C;&#x662F;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x4EFB;&#x52A1;&#x3002;"></p>
<p>&#x5728;&#x8FD9;&#x4E00;&#x7AE0;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x6DF1;&#x5165;&#x7814;&#x7A76;&#x4E86;S2S&#x6A21;&#x578B;&#xFF0C;&#x5E76;&#x5728;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x4EFB;&#x52A1;&#x7684;&#x80CC;&#x666F;&#x4E0B;&#x8FDB;&#x884C;&#x4E86;&#x8BF4;&#x660E;&#x3002;&#x8003;&#x8651;&#x4E00;&#x4E2A;&#x201C;&#x667A;&#x80FD;&#x201D;&#x7684;iOS/Android&#x952E;&#x76D8;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x5728;&#x4F60;&#x6253;&#x5B57;&#x65F6;&#x81EA;&#x52A8;&#x5C06;&#x6587;&#x672C;&#x8F6C;&#x6362;&#x6210;&#x8868;&#x60C5;&#x7B26;&#x53F7;&#x3002;&#x5982;&#x679C;&#x4F60;&#x8F93;&#x5165;&#x201C;omg!&#x201D;&#x623F;&#x5B50;&#x7740;&#x706B;&#x4E86;!&#xFF0C;&#x4F60;&#x5E0C;&#x671B;&#x952E;&#x76D8;&#x8F93;&#x51FA;&#x7C7B;&#x4F3C;&#x5185;&#x8054;&#x8F93;&#x51FA;&#x7684;&#x5185;&#x5BB9;&#x3002;&#x6CE8;&#x610F;&#xFF0C;&#x8F93;&#x51FA;&#x7684;&#x957F;&#x5EA6;(4&#x4E2A;&#x4EE4;&#x724C;)&#x4E0E;&#x8F93;&#x5165;&#x7684;&#x957F;&#x5EA6;(6&#x4E2A;&#x4EE4;&#x724C;)&#x4E0D;&#x540C;&#x3002;&#x8F93;&#x51FA;&#x548C;&#x8F93;&#x5165;&#x4E4B;&#x95F4;&#x7684;&#x6620;&#x5C04;&#x79F0;&#x4E3A;&#x5BF9;&#x9F50;&#xFF0C;&#x5982;&#x56FE;8-3&#x6240;&#x793A;&#x3002; <img src="img/b7d81537e2e606730712b8dcdc5eb05f.jpg" alt="example2" title="&#x56FE;8 - 3&#x3002;&#x8868;&#x60C5;&#x7B26;&#x53F7;&#x7FFB;&#x8BD1;&#x662F;&#x4E00;&#x4E2A;S2S&#x9884;&#x6D4B;&#x95EE;&#x9898;:&#x4E24;&#x4E2A;&#x5E8F;&#x5217;&#x4E2D;&#x7B26;&#x53F7;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x9F50;&#x8868;&#x793A;&#x7FFB;&#x8BD1;&#x7B49;&#x503C;&#x3002;"> &#x540C;&#x6837;&#xFF0C;&#x5728;&#x672C;&#x4F8B;&#x4E2D;&#xFF0C;&#x8F93;&#x5165;&#x4E2D;&#x7684;&#x5355;&#x4E2A;&#x4EE4;&#x724C;&#x53EF;&#x4EE5;&#x5728;&#x8F93;&#x51FA;&#x4E2D;&#x751F;&#x6210;&#x96F6;&#x4E2A;&#x6216;&#x591A;&#x4E2A;&#x4EE4;&#x724C;&#x3002;&#x4F20;&#x7EDF;&#x4E0A;&#xFF0C;&#x8BB8;&#x591A;&#x89E3;&#x51B3;S2S&#x95EE;&#x9898;&#x7684;&#x65B9;&#x6CD5;&#x90FD;&#x662F;&#x5C1D;&#x8BD5;&#x4F7F;&#x7528;&#x5DE5;&#x7A0B;&#x548C;&#x542F;&#x53D1;&#x5F0F;&#x91CD;&#x7EDF;&#x8BA1;&#x65B9;&#x6CD5;&#x3002;&#x867D;&#x7136;&#x56DE;&#x987E;&#x8FD9;&#x4E9B;&#x65B9;&#x6CD5;&#x8D85;&#x51FA;&#x4E86;&#x672C;&#x7AE0;&#x548C;&#x672C;&#x4E66;&#x7684;&#x8303;&#x56F4;&#xFF0C;&#x4F46;&#x662F;&#x6211;&#x4EEC;&#x5EFA;&#x8BAE;&#x60A8;&#x9605;&#x8BFB;Koehn(2009)&#x5E76;&#x53C2;&#x8003;statmt.org&#x4E2D;&#x7684;&#x53C2;&#x8003;&#x8D44;&#x6599;&#x3002;</p>
<p>&#x5728;&#x7B2C;6&#x7AE0;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5B66;&#x4E60;&#x4E86;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#x5982;&#x4F55;&#x5C06;&#x4EFB;&#x610F;&#x957F;&#x5EA6;&#x7684;&#x5E8F;&#x5217;&#x7F16;&#x7801;&#x6210;&#x5411;&#x91CF;&#x3002;&#x5728;&#x7B2C;7&#x7AE0;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x770B;&#x5230;&#x5355;&#x4E2A;&#x5411;&#x91CF;&#x5982;&#x4F55;&#x4F7F;&#x9012;&#x5F52;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;(RNN)&#x6709;&#x6761;&#x4EF6;&#x5730;&#x4EA7;&#x751F;&#x4E0D;&#x540C;&#x7684;&#x59D3;&#x6C0F;&#x3002;S2S&#x6A21;&#x578B;&#x662F;&#x8FD9;&#x4E9B;&#x6982;&#x5FF5;&#x7684;&#x81EA;&#x7136;&#x5EF6;&#x4F38;&#x3002;</p>
<p>&#x56FE;8 - 4&#x663E;&#x793A;&#x4E86;&#x7F16;&#x7801;&#x5668;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x4E00;&#x4E2A;&#x8868;&#x793A;&#x201C;&#x7F16;&#x7801;&#x201D;,&#x3D5;,&#x6761;&#x4EF6;&#x89E3;&#x7801;&#x5668;&#x751F;&#x6210;&#x6B63;&#x786E;&#x7684;&#x8F93;&#x51FA;&#x3002;&#x60A8;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4EFB;&#x4F55;RNN&#x4F5C;&#x4E3A;&#x7F16;&#x7801;&#x5668;&#xFF0C;&#x65E0;&#x8BBA;&#x662F;Elman RNN, Long - term Memory (LSTM)&#xFF0C;&#x8FD8;&#x662F;gate Unit (GRU)&#xFF0C;&#x3002;&#x5728;&#x63A5;&#x4E0B;&#x6765;&#x7684;&#x4E24;&#x4E2A;&#x90E8;&#x5206;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x4ECB;&#x7ECD;&#x73B0;&#x4EE3;S2S&#x6A21;&#x578B;&#x7684;&#x4E24;&#x4E2A;&#x91CD;&#x8981;&#x7EC4;&#x4EF6;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x6211;&#x4EEC;&#x5F15;&#x5165;&#x4E86;&#x53CC;&#x5411;&#x9012;&#x5F52;&#x6A21;&#x578B;&#xFF0C;&#x8BE5;&#x6A21;&#x578B;&#x5C06;&#x5411;&#x524D;&#x548C;&#x5411;&#x540E;&#x4F20;&#x9012;&#x7EC4;&#x5408;&#x5728;&#x4E00;&#x4E2A;&#x5E8F;&#x5217;&#x4E0A;&#xFF0C;&#x4EE5;&#x521B;&#x5EFA;&#x66F4;&#x4E30;&#x5BCC;&#x7684;&#x8868;&#x793A;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x5728;&#x201C;&#x4ECE;&#x5E8F;&#x5217;&#x4E2D;&#x83B7;&#x53D6;&#x66F4;&#x591A;&#x4FE1;&#x606F;:&#x6CE8;&#x610F;&#x529B;&#x201D;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x4ECB;&#x7ECD;&#x5E76;&#x8003;&#x5BDF;&#x4E86;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#xFF0C;&#x5B83;&#x5728;&#x5173;&#x6CE8;&#x4E0E;&#x4EFB;&#x52A1;&#x76F8;&#x5173;&#x7684;&#x8F93;&#x5165;&#x7684;&#x4E0D;&#x540C;&#x90E8;&#x5206;&#x65F6;&#x975E;&#x5E38;&#x6709;&#x7528;&#x3002;&#x8FD9;&#x4E24;&#x4E2A;&#x90E8;&#x5206;&#x5BF9;&#x4E8E;&#x6784;&#x5EFA;&#x57FA;&#x4E8E;S2S&#x6A21;&#x578B;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x90FD;&#x975E;&#x5E38;&#x91CD;&#x8981;&#x3002;</p>
<p><img src="img/d9e36aa0f27f4c63020a354160813b95.jpg" alt="example3" title="&#x56FE;8-4\. S2S&#x6A21;&#x5F0F;&#xFF0C;&#x7528;&#x4E8E;&#x5C06;&#x82F1;&#x8BED;&#x7FFB;&#x8BD1;&#x6210;&#x8868;&#x60C5;&#x7B26;&#x53F7;&#x3002;"></p>
<h2 id="capturing-more-from-a-sequence-bidirectional-recurrent-models">Capturing More from a Sequence: Bidirectional Recurrent Models</h2>
<p>&#x7406;&#x89E3;&#x9012;&#x5F52;&#x6A21;&#x578B;&#x7684;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x662F;&#x628A;&#x5B83;&#x770B;&#x4F5C;&#x4E00;&#x4E2A;&#x5C06;&#x5E8F;&#x5217;&#x7F16;&#x7801;&#x4E3A;&#x5411;&#x91CF;&#x7684;&#x9ED1;&#x76D2;&#x5B50;&#x3002;&#x5728;&#x5EFA;&#x6A21;&#x5E8F;&#x5217;&#x65F6;&#xFF0C;&#x4E0D;&#x4EC5;&#x8981;&#x89C2;&#x5BDF;&#x8FC7;&#x53BB;&#x7684;&#x5355;&#x8BCD;&#xFF0C;&#x800C;&#x4E14;&#x8FD8;&#x8981;&#x89C2;&#x5BDF;&#x5C06;&#x6765;&#x51FA;&#x73B0;&#x7684;&#x5355;&#x8BCD;&#x3002;&#x8003;&#x8651;&#x4EE5;&#x4E0B;&#x53E5;&#x5B50;:</p>
<p>The man who hunts ducks out on the weekends. &#x5982;&#x679C;&#x6A21;&#x578B;&#x53EA;&#x4ECE;&#x5DE6;&#x5230;&#x53F3;&#x89C2;&#x5BDF;&#xFF0C;&#x90A3;&#x4E48;&#x201C;duck&#x201D;&#x7684;&#x8868;&#x793A;&#x5C06;&#x4E0D;&#x540C;&#x4E8E;&#x4ECE;&#x53F3;&#x5230;&#x5DE6;&#x89C2;&#x5BDF;&#x5355;&#x8BCD;&#x7684;&#x6A21;&#x578B;&#x3002;&#x4EBA;&#x7C7B;&#x4E00;&#x76F4;&#x5728;&#x505A;&#x8FD9;&#x79CD;&#x56DE;&#x6EAF;&#x6027;&#x7684;&#x66F4;&#x65B0;&#x3002;</p>
<p>&#x56E0;&#x6B64;&#xFF0C;&#x5982;&#x679C;&#x628A;&#x8FC7;&#x53BB;&#x548C;&#x672A;&#x6765;&#x7684;&#x4FE1;&#x606F;&#x7ED3;&#x5408;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x5C31;&#x80FD;&#x591F;&#x6709;&#x529B;&#x5730;&#x6309;&#x987A;&#x5E8F;&#x8868;&#x793A;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;&#x7684;&#x610F;&#x601D;&#x3002;&#x8FD9;&#x5C31;&#x662F;&#x53CC;&#x5411;&#x9012;&#x5F52;&#x6A21;&#x578B;&#x7684;&#x76EE;&#x6807;&#x3002;&#x9012;&#x5F52;&#x5BB6;&#x65CF;&#x7684;&#x4EFB;&#x4F55;&#x6A21;&#x578B;&#xFF0C;&#x5982;Elmann RNNs&#x6216;LSTMs&#x6216;GRUs&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x8FD9;&#x79CD;&#x53CC;&#x5411;&#x8868;&#x8FBE;&#x3002;&#x4E0E;&#x7B2C;6&#x7AE0;&#x548C;&#x7B2C;7&#x7AE0;&#x4E2D;&#x7684;&#x5355;&#x5411;&#x6A21;&#x578B;&#x4E00;&#x6837;&#xFF0C;&#x53CC;&#x5411;&#x6A21;&#x578B;&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x5206;&#x7C7B;&#x548C;&#x5E8F;&#x5217;&#x6807;&#x8BB0;&#x8BBE;&#x7F6E;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x9884;&#x6D4B;&#x8F93;&#x5165;&#x4E2D;&#x6BCF;&#x4E2A;&#x5355;&#x8BCD;&#x7684;&#x4E00;&#x4E2A;&#x6807;&#x7B7E;&#x3002;&#x56FE;8-5&#x548C;&#x56FE;8-6&#x8BE6;&#x7EC6;&#x8BF4;&#x660E;&#x4E86;&#x8FD9;&#x4E00;&#x70B9;&#x3002;&#x5728;&#x56FE;8-6&#x4E2D;&#xFF0C;<script type="math/tex; ">ϕ_{love}</script> &#x662F;&#x8868;&#x793A;&#x3001;&#x7F16;&#x7801;&#x6216;&#x8BE5;&#x65F6;&#x523B;&#x7F51;&#x7EDC;&#x7684;&#x201C;&#x9690;&#x85CF;&#x7684;&#x72B6;&#x6001;&#x201D;,&#x5F53;&#x8F93;&#x5165;&#x7684;&#x8BCD;&#x662F;&#x201D;love&#x201D;&#x6B65;&#x3002;&#x5F53;&#x6211;&#x4EEC;&#x8BA8;&#x8BBA;&#x6CE8;&#x610F;&#x529B;&#x65F6;&#xFF0C;&#x8FD9;&#x79CD;&#x72B6;&#x6001;&#x4FE1;&#x606F;&#x5728;&#x201C;&#x4ECE;&#x4E00;&#x4E2A;&#x5E8F;&#x5217;&#x4E2D;&#x83B7;&#x53D6;&#x66F4;&#x591A;&#x4FE1;&#x606F;:&#x6CE8;&#x610F;&#x529B;&#x201D;&#x4E2D;&#x53D8;&#x5F97;&#x5F88;&#x91CD;&#x8981;&#x3002;</p>
<p><img src="img/b74e4cae22941eb118bc6f363c85fa2d.jpg" alt="Attention" title="&#x56FE;8-5\. &#x7528;&#x4E8E;&#x5E8F;&#x5217;&#x5206;&#x7C7B;&#x7684;&#x53CC;&#x5411;RNN&#x6A21;&#x578B;&#x3002;&#x6CE8;&#x610F;&#x6A21;&#x578B;&#x201C;&#x8BFB;&#x53D6;&#x201D;&#x8FD9;&#x53E5;&#x8BDD;&#x5728;&#x8FD9;&#x4E24;&#x4E2A;&#x65B9;&#x5411;,&#x5E76;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x53E5;&#x5B50;&#x8868;&#x793A;&#x3D5;&#x7684;&#x4F5C;&#x6587;&#x5411;&#x524D;&#x548C;&#x5411;&#x540E;&#x8868;&#x793A;&#x3002;&#x8FD9;&#x91CC;&#x6CA1;&#x6709;&#x663E;&#x793A;&#x7684;&#x662F;&#x7531;&#x7EBF;&#x6027;&#x5C42;&#x548C;softmax&#x7EC4;&#x6210;&#x7684;&#x6700;&#x7EC8;&#x5206;&#x7C7B;&#x5C42;&#x3002;"> <img src="img/d6df8a4d46a3f6a19896d574f58dbbb2.jpg" alt="Attention2" title="&#x56FE;8-6&#x3002;&#x7528;&#x4E8E;&#x5E8F;&#x5217;&#x6807;&#x8BB0;&#x7684;&#x53CC;&#x5411;&#x9012;&#x5F52;&#x6A21;&#x578B;&#x3002;&#x6CE8;&#x610F;&#x8F93;&#x5165;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x5355;&#x8BCD;&#x662F;&#x5982;&#x4F55;&#x5B58;&#x5728;&#x201C;&#x524D;&#x5411;&#x201D;&#x8868;&#x793A;&#x548C;&#x201C;&#x540E;&#x5411;&#x201D;&#x8868;&#x793A;&#xFF0C;&#x5B83;&#x4EEC;&#x88AB;&#x8FDE;&#x63A5;&#x8D77;&#x6765;&#x4EE5;&#x4EA7;&#x751F;&#x6240;&#x8BA8;&#x8BBA;&#x5355;&#x8BCD;&#x7684;&#x6700;&#x7EC8;&#x8868;&#x793A;&#x3002;&#x8FD9;&#x91CC;&#x6CA1;&#x6709;&#x663E;&#x793A;&#x7684;&#x662F;&#x6700;&#x7EC8;&#x5206;&#x7C7B;&#x5C42;&#xFF0C;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x7531;&#x7EBF;&#x6027;&#x5C42;&#x548C;softmax&#x7EC4;&#x6210;&#x3002;"></p>
<h2 id="capturing-more-from-a-sequence-attention">Capturing More from a Sequence: Attention</h2>
<p>&#x201C;&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#xFF0C;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x548C;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x201D;&#x4E2D;&#x5F15;&#x5165;&#x7684;S2S&#x6A21;&#x578B;&#x516C;&#x5F0F;&#x7684;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#x662F;&#x5B83;&#x5C06;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x53E5;&#x5B50;&#x53D8;&#x6210;&#x5355;&#x4E2A;&#x77E2;&#x91CF;&#xFF08;&#x201C;&#x7F16;&#x7801;&#x201D;&#xFF09;&#x3C6;&#x5E76;&#x4F7F;&#x7528;&#x8BE5;&#x7F16;&#x7801;&#x751F;&#x6210;&#x8F93;&#x51FA;&#xFF0C;&#x5982;&#x56FE;8-7&#x6240;&#x793A;&#x3002;&#x867D;&#x7136;&#x8FD9;&#x53EF;&#x80FD;&#x9002;&#x7528;&#x4E8E;&#x975E;&#x5E38;&#x77ED;&#x7684;&#x53E5;&#x5B50;&#xFF0C;&#x4F46;&#x5BF9;&#x4E8E;&#x957F;&#x53E5;&#xFF0C;&#x8FD9;&#x6837;&#x7684;&#x6A21;&#x578B;&#x65E0;&#x6CD5;&#x6355;&#x83B7;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x4E2D;&#x7684;&#x4FE1;&#x606F;;&#x4F8B;&#x5982;&#xFF0C;&#x89C1;Bengio&#x7B49;&#x3002; &#xFF08;1994&#xFF09;&#x548C;Le&#x548C;Zuidema&#xFF08;2016&#xFF09;&#x3002;&#x8FD9;&#x662F;&#x4EC5;&#x4F7F;&#x7528;&#x6700;&#x7EC8;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4F5C;&#x4E3A;&#x7F16;&#x7801;&#x7684;&#x9650;&#x5236;&#x3002;&#x957F;&#x8F93;&#x5165;&#x7684;&#x53E6;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#x662F;&#xFF0C;&#x5F53;&#x957F;&#x65F6;&#x95F4;&#x8F93;&#x5165;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x65F6;&#xFF0C;&#x68AF;&#x5EA6;&#x6D88;&#x5931;&#xFF0C;&#x4F7F;&#x8BAD;&#x7EC3;&#x53D8;&#x5F97;&#x56F0;&#x96BE;&#x3002; <img src="img/63c2d0fdd2e3d4fc9ebaa90f29949bce.jpg" alt="Attention3" title="&#x56FE;8-7.&#x4F7F;&#x7528;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x5C06;&#x957F;&#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#x7FFB;&#x8BD1;&#x6210;&#x82F1;&#x8BED;&#x3002;&#x6700;&#x7EC8;&#x8868;&#x793A;&#x3C6;&#x65E0;&#x6CD5;&#x6355;&#x83B7;&#x8F93;&#x5165;&#x4E2D;&#x7684;&#x957F;&#x7A0B;&#x4F9D;&#x8D56;&#x6027;&#x5E76;&#x4F7F;&#x8BAD;&#x7EC3;&#x53D8;&#x5F97;&#x56F0;&#x96BE;&#x3002;"> &#x5BF9;&#x4E8E;&#x66FE;&#x5C1D;&#x8BD5;&#x7FFB;&#x8BD1;&#x7684;&#x53CC;&#x8BED;/&#x591A;&#x8BED;&#x8A00;&#x8BFB;&#x8005;&#x6765;&#x8BF4;&#xFF0C;&#x8FD9;&#x79CD;&#x9996;&#x5148;&#x7F16;&#x7801;&#x7136;&#x540E;&#x89E3;&#x7801;&#x7684;&#x8FC7;&#x7A0B;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x70B9;&#x5947;&#x602A;&#x3002;&#x4F5C;&#x4E3A;&#x4EBA;&#x7C7B;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x5E38;&#x4E0D;&#x4F1A;&#x63D0;&#x70BC;&#x53E5;&#x5B50;&#x7684;&#x542B;&#x4E49;&#x5E76;&#x4ECE;&#x610F;&#x4E49;&#x4E2D;&#x4EA7;&#x751F;&#x7FFB;&#x8BD1;&#x3002;&#x5BF9;&#x4E8E;&#x56FE;8-7&#x4E2D;&#x7684;&#x793A;&#x4F8B;&#xFF0C;&#x201C;pour&#x201D; we know there will be a &#x201C;for&#x201D;; similarly &#x201C;breakfast&#x201D; is on our mind when we see &#x201C;petit-d&#xE9;jeuner,&#x201D; and so on. In other words, our mind focuses on the relevant parts of the input while producing output. This phenomenon is called attention. Attention has been widely studied in neuroscience and other allied fields, and it is what makes us quite successful despite having limited memories. Attention happens everywhere. In fact, it is happening right now to you, dear reader. Each. Word. You. Are. Reading. Now. Is. Being. Attended. To. Even if you have an exceptional memory, you&#x2019;re probably not reading this entire book as a string. When you are reading a word, you are paying attention to the neighboring word, possibly the topic of the Section and Chapter, and so on.</p>
<p>&#x4EE5;&#x7C7B;&#x4F3C;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x5C06;&#x6CE8;&#x610F;&#x529B;&#x96C6;&#x4E2D;&#x5230;&#x8F93;&#x5165;&#x7684;&#x4E0D;&#x540C;&#x90E8;&#x5206;&#xFF0C;&#x800C;&#x4E0D;&#x4EC5;&#x4EC5;&#x662F;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x7684;&#x6700;&#x7EC8;&#x603B;&#x7ED3;&#x3002;&#x8FD9;&#x5C31;&#x662F;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x3002;&#x7B2C;&#x4E00;&#x4E2A;&#x5305;&#x542B;&#x81EA;&#x7136;&#x8BED;&#x8A00;&#x5904;&#x7406;(NLP)&#x6CE8;&#x610F;&#x6982;&#x5FF5;&#x7684;&#x6A21;&#x578B;&#x662F;Bahdanau&#x7B49;&#x4EBA;(2015)&#x7684;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x6A21;&#x578B;&#x3002;&#x4ECE;&#x90A3;&#x65F6;&#x8D77;&#xFF0C;&#x4EBA;&#x4EEC;&#x63D0;&#x51FA;&#x4E86;&#x51E0;&#x79CD;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x548C;&#x63D0;&#x9AD8;&#x6CE8;&#x610F;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x5728;&#x672C;&#x8282;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x56DE;&#x987E;&#x4E00;&#x4E9B;&#x57FA;&#x672C;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#xFF0C;&#x5E76;&#x4ECB;&#x7ECD;&#x4E00;&#x4E9B;&#x4E0E;&#x6CE8;&#x610F;&#x76F8;&#x5173;&#x7684;&#x672F;&#x8BED;&#x3002;&#x4E8B;&#x5B9E;&#x8BC1;&#x660E;&#xFF0C;&#x6CE8;&#x610F;&#x529B;&#x5BF9;&#x4E8E;&#x6539;&#x8FDB;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x590D;&#x6742;&#x7684;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7CFB;&#x7EDF;&#x975E;&#x5E38;&#x6709;&#x7528;&#x3002;&#x4E8B;&#x5B9E;&#x4E0A;&#xFF0C;Bahdanau&#x7B49;&#x4EBA;&#x901A;&#x8FC7;&#x201C;BLEU score&#x201D;(&#x6211;&#x4EEC;&#x5728;&#x201C;&#x8BC4;&#x4F30;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x201D;&#x4E2D;&#x770B;&#x5230;&#x7684;)&#x6765;&#x8861;&#x91CF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x7CFB;&#x7EDF;&#x7684;&#x6027;&#x80FD;&#xFF0C;&#x5F53;&#x8F93;&#x5165;&#x53D8;&#x957F;&#x65F6;&#xFF0C;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x7CFB;&#x7EDF;&#x5728;&#x6CA1;&#x6709;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x4F1A;&#x4E0B;&#x964D;&#xFF0C;&#x5982;&#x56FE;8-8&#x6240;&#x793A;&#x3002;&#x589E;&#x52A0;&#x6CE8;&#x610F;&#x529B;&#x53EF;&#x4EE5;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#x3002;</p>
<p><img src="img/6fcf2d19b01740d36c409edb3500f7a3.jpg" alt="example4" title="&#x56FE;8-8\. &#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;&#x6CE8;&#x610F;&#xFF1F;&#x8BE5;&#x56FE;&#x8868;&#x663E;&#x793A;&#x4E86;&#x5177;&#x6709;&#xFF08;RNNsearch-30&#xFF0C;RNNsearch-50&#xFF09;&#x548C;&#x6CA1;&#x6709;&#xFF08;RNNenc-30&#xFF0C;RNNenc-50&#xFF09;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x7CFB;&#x7EDF;&#x7684;BLEU&#x5206;&#x6570;&#x7684;&#x53D8;&#x5316;&#x3002; RNN * -30&#x548C;RNN * -50&#x7CFB;&#x7EDF;&#x5206;&#x522B;&#x7528;&#x957F;&#x8FBE;30&#x548C;50&#x4E2A;&#x5355;&#x8BCD;&#x7684;&#x53E5;&#x5B50;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x3002;&#x5728;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x7CFB;&#x7EDF;&#x4E2D;&#xFF0C;&#x6CA1;&#x6709;&#x6CE8;&#x610F;&#xFF0C;&#x7CFB;&#x7EDF;&#x7684;&#x6027;&#x80FD;&#x968F;&#x7740;&#x53E5;&#x5B50;&#x957F;&#x5EA6;&#x7684;&#x589E;&#x52A0;&#x800C;&#x964D;&#x4F4E;&#x3002;&#x901A;&#x8FC7;&#x6CE8;&#x610F;&#xFF0C;&#x8F83;&#x957F;&#x53E5;&#x5B50;&#x7684;&#x7FFB;&#x8BD1;&#x5F97;&#x5230;&#x6539;&#x5584;&#xFF0C;&#x4F46;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x6027;&#x80FD;&#x7684;&#x7A33;&#x5B9A;&#x6027;&#x4E0E;&#x8BAD;&#x7EC3;&#x5B83;&#x7684;&#x53E5;&#x5B50;&#x7684;&#x957F;&#x5EA6;&#x6709;&#x5173;&#x3002; &#xFF08;&#x56FE;&#x7531;Bahdanau&#x7B49;&#x4EBA;&#x63D0;&#x4F9B;[2015]&#xFF09;"></p>
<h3 id="attention-in-deep-neural-networks">Attention in Deep Neural Networks</h3>
<p>&#x6CE8;&#x610F;&#x529B;&#x662F;&#x4E00;&#x79CD;&#x901A;&#x7528;&#x7684;&#x673A;&#x5236;&#xFF0C;&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x672C;&#x4E66;&#x524D;&#x9762;&#x8BA8;&#x8BBA;&#x8FC7;&#x7684;&#x4EFB;&#x4F55;&#x4E00;&#x79CD;&#x6A21;&#x578B;&#x3002;&#x4F46;&#x6211;&#x4EEC;&#x5728;&#x8FD9;&#x91CC;&#x7528;&#x7F16;&#x7801;&#x5668;-&#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x6765;&#x63CF;&#x8FF0;&#x5B83;&#xFF0C;&#x56E0;&#x4E3A;&#x8FD9;&#x4E9B;&#x6A21;&#x578B;&#x662F;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x771F;&#x6B63;&#x53D1;&#x6325;&#x4F5C;&#x7528;&#x7684;&#x5730;&#x65B9;&#x3002;&#x8003;&#x8651;&#x4E00;&#x4E2A;S2S&#x6A21;&#x578B;&#x3002;&#x56DE;&#x60F3;&#x4E00;&#x4E0B;,&#x5728;&#x4E00;&#x4E2A;&#x5178;&#x578B;&#x7684;S2S&#x6A21;&#x578B;&#x4E2D;,&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x9690;&#x85CF;&#x7684;&#x72B6;&#x6001;&#x8868;&#x793A;,&#x8868;&#x793A; <script type="math/tex; ">ϕ_w</script>,&#x7279;&#x5B9A;&#x4E8E;&#x8BE5;&#x65F6;&#x95F4;&#x6B65;&#x7684;&#x7F16;&#x7801;&#x5668;&#x3002;(&#x5982;&#x56FE;8-6&#x6240;&#x793A;&#x3002;)&#x4E3A;&#x4E86;&#x5F15;&#x8D77;&#x6CE8;&#x610F;&#xFF0C;&#x6211;&#x4EEC;&#x4E0D;&#x4EC5;&#x8981;&#x8003;&#x8651;&#x7F16;&#x7801;&#x5668;&#x7684;&#x6700;&#x7EC8;&#x9690;&#x85CF;&#x72B6;&#x6001;&#xFF0C;&#x8FD8;&#x8981;&#x8003;&#x8651;&#x6BCF;&#x4E2A;&#x4E2D;&#x95F4;&#x6B65;&#x9AA4;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x3002;&#x8FD9;&#x4E9B;&#x7F16;&#x7801;&#x5668;&#x9690;&#x85CF;&#x72B6;&#x6001;&#xFF0C;&#x5728;&#x67D0;&#x79CD;&#x7A0B;&#x5EA6;&#x4E0A;&#x662F;&#x975E;&#x4FE1;&#x606F;&#x6027;&#x7684;&#xFF0C;&#x79F0;&#x4E3A;&#x503C;&#x3002;&#x5728;&#x67D0;&#x4E9B;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x7F16;&#x7801;&#x5668;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4E5F;&#x79F0;&#x4E3A;&#x952E;&#x3002;&#x6CE8;&#x610F;&#x529B;&#x8FD8;&#x53D6;&#x51B3;&#x4E8E;&#x8C03;&#x7528;&#x67E5;&#x8BE2;&#x7684;&#x89E3;&#x7801;&#x5668;&#x7684;&#x524D;&#x4E00;&#x4E2A;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x3002;&#x56FE;8-9&#x8BF4;&#x660E;&#x4E86;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;0&#x7684;&#x6240;&#x6709;&#x8FD9;&#x4E9B;&#x3002;&#x65F6;&#x95F4;&#x6B65;&#x957F;t=0&#x7684;&#x67E5;&#x8BE2;&#x5411;&#x91CF;&#x662F;&#x4E00;&#x4E2A;&#x56FA;&#x5B9A;&#x7684;&#x8D85;&#x53C2;&#x6570;&#x3002;&#x6CE8;&#x610F;&#x7531;&#x4E00;&#x4E2A;&#x5411;&#x91CF;&#x6765;&#x8868;&#x793A;&#xFF0C;&#x8FD9;&#x4E2A;&#x5411;&#x91CF;&#x7684;&#x7EF4;&#x6570;&#x4E0E;&#x5B83;&#x6240;&#x5173;&#x6CE8;&#x7684;&#x503C;&#x7684;&#x7EF4;&#x6570;&#x76F8;&#x540C;&#x3002;&#x8FD9;&#x88AB;&#x79F0;&#x4E3A;&#x6CE8;&#x610F;&#x529B;&#x5411;&#x91CF;&#xFF0C;&#x6216;&#x6CE8;&#x610F;&#x529B;&#x6743;&#x91CD;&#xFF0C;&#x6709;&#x65F6;&#x4E5F;&#x79F0;&#x4E3A;&#x5BF9;&#x9F50;&#x3002;&#x6CE8;&#x610F;&#x529B;&#x6743;&#x91CD;&#x4E0E;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;(&#x201C;&#x503C;&#x201D;)&#x76F8;&#x7ED3;&#x5408;&#xFF0C;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x6709;&#x65F6;&#x4E5F;&#x79F0;&#x4E3A;&#x77A5;&#x89C1;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x3002;&#x8FD9;&#x4E2A;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x6210;&#x4E3A;&#x89E3;&#x7801;&#x5668;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x5B8C;&#x6574;&#x7684;&#x53E5;&#x5B50;&#x7F16;&#x7801;&#x3002;&#x4F7F;&#x7528;&#x517C;&#x5BB9;&#x6027;&#x51FD;&#x6570;&#x66F4;&#x65B0;&#x4E0B;&#x4E00;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x7684;&#x6CE8;&#x610F;&#x5411;&#x91CF;&#x3002;&#x76F8;&#x5BB9;&#x51FD;&#x6570;&#x7684;&#x786E;&#x5207;&#x6027;&#x8D28;&#x53D6;&#x51B3;&#x4E8E;&#x6240;&#x4F7F;&#x7528;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x3002;</p>
<p><img src="img/e9a33e716b27aa7486aa9abbfa4f93e8.jpg" alt="Encoder_Decoder" title="&#x56FE;8-9\. &#x65F6;&#x95F4;&#x6B65;&#x957F;t=0&#x65F6;&#x7684;&#x6CE8;&#x610F;&#x3002;&#x9884;&#x6D4B;&#x7684;&#x8F93;&#x51FA;&#x662F;&#x201C;&#x5BF9;&#x201D;&#x548C;&#x5173;&#x6CE8;&#x5757;&#x8003;&#x8651;&#x9690;&#x72B6;&#x6001;&#x7684;&#x7F16;&#x7801;&#x5668;&#x3D5;w&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5355;&#x8BCD;&#x3002;&#x8981;&#x8BE6;&#x7EC6;&#x4E86;&#x89E3;&#x8FD9;&#x4E2A;&#x56FE;&#xFF08;&#x6211;&#x4EEC;&#x5F3A;&#x70C8;&#x63A8;&#x8350;&#xFF09;&#xFF0C;&#x8BF7;&#x53C2;&#x89C1;&#x201C;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x201D;&#x3002;"> &#x6709;&#x51E0;&#x79CD;&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;&#x5173;&#x6CE8;&#x3002;&#x6700;&#x7B80;&#x5355;&#x548C;&#x6700;&#x5E38;&#x7528;&#x7684;&#x662F;&#x5185;&#x5BB9;&#x611F;&#x77E5;&#x673A;&#x5236;&#x3002;&#x60A8;&#x53EF;&#x4EE5;&#x5728;&#x201C;&#x793A;&#x4F8B;&#xFF1A;&#x795E;&#x7ECF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x201D;&#x4E2D;&#x770B;&#x5230;&#x5185;&#x5BB9;&#x611F;&#x77E5;&#x6CE8;&#x610F;&#x529B;&#x3002;&#x53E6;&#x4E00;&#x79CD;&#x6D41;&#x884C;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x662F;&#x4F4D;&#x7F6E;&#x611F;&#x77E5;&#x6CE8;&#x610F;&#x529B;&#xFF0C;&#x5B83;&#x4EC5;&#x4F9D;&#x8D56;&#x4E8E;&#x67E5;&#x8BE2;&#x5411;&#x91CF;&#x548C;&#x5BC6;&#x94A5;&#x3002;&#x6CE8;&#x610F;&#x6743;&#x91CD;&#x901A;&#x5E38;&#x662F;0&#x5230;1&#x4E4B;&#x95F4;&#x7684;&#x6D6E;&#x70B9;&#x503C;&#x3002;&#x8FD9;&#x79F0;&#x4E3A;&#x8F6F;&#x6CE8;&#x610F;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x53EF;&#x4EE5;&#x5B66;&#x4E60;&#x4E8C;&#x8FDB;&#x5236;0/1&#x5411;&#x91CF;&#x4EE5;&#x5F15;&#x8D77;&#x6CE8;&#x610F;&#x3002;&#x8FD9;&#x88AB;&#x79F0;&#x4E3A;&#x786C;&#x5173;&#x6CE8;&#x3002;</p>
<p>&#x56FE;8-9&#x4E2D;&#x6240;&#x793A;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x53D6;&#x51B3;&#x4E8E;&#x8F93;&#x5165;&#x4E2D;&#x6240;&#x6709;&#x65F6;&#x95F4;&#x6B65;&#x957F;&#x7684;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x3002;&#x8FD9;&#x4E5F;&#x88AB;&#x79F0;&#x4E3A;&#x5168;&#x7403;&#x5173;&#x6CE8;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x5BF9;&#x4E8E;&#x672C;&#x5730;&#x6CE8;&#x610F;&#x529B;&#xFF0C;&#x60A8;&#x53EF;&#x4EE5;&#x8BBE;&#x8BA1;&#x4E00;&#x79CD;&#x6CE8;&#x610F;&#x673A;&#x5236;&#xFF0C;&#x8BE5;&#x673A;&#x5236;&#x4EC5;&#x4F9D;&#x8D56;&#x4E8E;&#x5F53;&#x524D;&#x65F6;&#x95F4;&#x6B65;&#x957F;&#x5468;&#x56F4;&#x7684;&#x8F93;&#x5165;&#x7A97;&#x53E3;&#x3002;</p>
<p>&#x6709;&#x65F6;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x5728;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x4E2D;&#xFF0C;&#x53EF;&#x4EE5;&#x660E;&#x786E;&#x5730;&#x63D0;&#x4F9B;&#x5BF9;&#x9F50;&#x4FE1;&#x606F;&#x4F5C;&#x4E3A;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x7684;&#x4E00;&#x90E8;&#x5206;&#x3002;&#x5728;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x53EF;&#x4EE5;&#x8BBE;&#x8BA1;&#x53D7;&#x76D1;&#x7763;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x6765;&#x4F7F;&#x7528;&#x5171;&#x540C;&#x8BAD;&#x7EC3;&#x7684;&#x5355;&#x72EC;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6765;&#x5B66;&#x4E60;&#x6CE8;&#x610F;&#x529B;&#x529F;&#x80FD;&#x3002;&#x5BF9;&#x4E8E;&#x8BF8;&#x5982;&#x6587;&#x6863;&#x4E4B;&#x7C7B;&#x7684;&#x5927;&#x578B;&#x8F93;&#x5165;&#xFF0C;&#x53EF;&#x4EE5;&#x8BBE;&#x8BA1;&#x7C97;&#x7C92;&#x5EA6;&#x5230;&#x7EC6;&#x7C92;&#x5EA6;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#xFF0C;&#x4E5F;&#x79F0;&#x4E3A;&#x5206;&#x7EA7;&#x6CE8;&#x610F;&#xFF0C;&#x4E0D;&#x4EC5;&#x5173;&#x6CE8;&#x7ACB;&#x5373;&#x8F93;&#x5165;&#xFF0C;&#x800C;&#x4E14;&#x8FD8;&#x8003;&#x8651;&#x6587;&#x6863;&#x7684;&#x7ED3;&#x6784; - &#x6BB5;&#x843D;&#xFF0C;&#x90E8;&#x5206;&#xFF0C;&#x7AE0;&#x8282;&#x7B49;&#x3002; Vaswani&#x7B49;&#x4EBA;&#x5BF9;&#x53D8;&#x538B;&#x5668;&#x7F51;&#x7EDC;&#x7684;&#x7814;&#x7A76;&#x3002; &#xFF08;2017&#xFF09;&#xFF0C;&#x5F15;&#x5165;&#x591A;&#x5934;&#x6CE8;&#x610F;&#xFF0C;&#x5176;&#x4E2D;&#x591A;&#x4E2A;&#x6CE8;&#x610F;&#x5411;&#x91CF;&#x7528;&#x4E8E;&#x8DDF;&#x8E2A;&#x8F93;&#x5165;&#x7684;&#x4E0D;&#x540C;&#x533A;&#x57DF;&#x3002;&#x4ED6;&#x4EEC;&#x8FD8;&#x666E;&#x53CA;&#x4E86;&#x81EA;&#x6211;&#x5173;&#x6CE8;&#x7684;&#x6982;&#x5FF5;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x673A;&#x5236;&#xFF0C;&#x901A;&#x8FC7;&#x8BE5;&#x673A;&#x5236;&#xFF0C;&#x6A21;&#x578B;&#x53EF;&#x4EE5;&#x4E86;&#x89E3;&#x8F93;&#x5165;&#x7684;&#x54EA;&#x4E9B;&#x533A;&#x57DF;&#x76F8;&#x4E92;&#x5F71;&#x54CD;&#x3002;</p>
<p>&#x5F53;&#x8F93;&#x5165;&#x662F;&#x591A;&#x6A21;&#x5F0F;&#x65F6; - &#x4F8B;&#x5982;&#xFF0C;&#x56FE;&#x50CF;&#x548C;&#x8BED;&#x97F3; - &#x53EF;&#x4EE5;&#x8BBE;&#x8BA1;&#x591A;&#x6A21;&#x5F0F;&#x6CE8;&#x610F;&#x529B;&#x3002;&#x5173;&#x4E8E;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x6587;&#x732E;&#x867D;&#x7136;&#x5F88;&#x65B0;&#xFF0C;&#x4F46;&#x5DF2;&#x7ECF;&#x975E;&#x5E38;&#x5E7F;&#x6CDB;&#xFF0C;&#x8FD9;&#x8868;&#x660E;&#x4E86;&#x8FD9;&#x4E00;&#x4E3B;&#x9898;&#x7684;&#x91CD;&#x8981;&#x6027;&#x3002;&#x8BE6;&#x7EC6;&#x4ECB;&#x7ECD;&#x5B83;&#x4EEC;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x90FD;&#x8D85;&#x51FA;&#x4E86;&#x672C;&#x4E66;&#x7684;&#x8303;&#x56F4;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5F15;&#x5BFC;&#x60A8;&#x5230;Luong&#xFF0C;Pham&#x548C;Manning&#xFF08;2011&#xFF09;&#x4EE5;&#x53CA;Vaswani&#x7B49;&#x4EBA;&#x3002; &#xFF08;2017&#xFF09;&#x4F5C;&#x4E3A;&#x8D77;&#x70B9;&#x3002;</p>
<h2 id="evaluating-sequence-generation-models">Evaluating Sequence Generation Models</h2>
<p>&#x5F53;&#x751F;&#x6210;&#x4EFB;&#x52A1;&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x591A;&#x4E2A;&#x6709;&#x6548;&#x7B54;&#x6848;&#x65F6;&#xFF0C;&#x7CBE;&#x5EA6;&#xFF0C;&#x53EC;&#x56DE;&#xFF0C;&#x51C6;&#x786E;&#x5EA6;&#x548C;F1&#x7B49;&#x5206;&#x7C7B;&#x6307;&#x6807;&#x65E0;&#x6CD5;&#x5E2E;&#x52A9;&#x6A21;&#x578B; - &#x5355;&#x4E2A;&#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#x53EF;&#x4EE5;&#x6709;&#x591A;&#x4E2A;&#x82F1;&#x8BED;&#x7FFB;&#x8BD1;&#x3002;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#x6839;&#x636E;&#x79F0;&#x4E3A;&#x53C2;&#x8003;&#x8F93;&#x51FA;&#x7684;&#x9884;&#x671F;&#x8F93;&#x51FA;&#x8FDB;&#x884C;&#x8BC4;&#x4F30;&#x3002;&#x5728;&#x6BD4;&#x8F83;&#x4E0D;&#x540C;&#x7684;&#x6A21;&#x578B;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x5206;&#x6570;&#x6765;&#x8868;&#x660E;&#x6A21;&#x578B;&#x8F93;&#x51FA;&#x7684;&#x201C;&#x826F;&#x597D;&#x201D;&#x4E0E;&#x53C2;&#x8003;&#x7684;&#x63A5;&#x8FD1;&#x7A0B;&#x5EA6;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5728;&#x50CF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x8FD9;&#x6837;&#x7684;&#x4EFB;&#x52A1;&#x4E2D;&#xFF0C;&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x6A21;&#x578B;&#x53EA;&#x6709;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;&#x5173;&#x95ED;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x80FD;&#x4E0D;&#x5E0C;&#x671B;&#x50CF;&#x53E6;&#x4E00;&#x4E2A;&#x4EA7;&#x751F;&#x5B8C;&#x5168;&#x65E0;&#x6CD5;&#x7406;&#x89E3;&#x7684;&#x7B54;&#x6848;&#x7684;&#x6A21;&#x578B;&#x90A3;&#x6837;&#x60E9;&#x7F5A;&#x8BE5;&#x6A21;&#x578B;&#x3002;&#x5355;&#x4E2A;&#x8F93;&#x5165;&#x793A;&#x4F8B;&#x53EF;&#x4EE5;&#x6709;&#x591A;&#x4E2A;&#x53C2;&#x8003;&#x8F93;&#x51FA;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5BF9;&#x4E8E;&#x7279;&#x5B9A;&#x7684;&#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#xFF0C;&#x53EF;&#x80FD;&#x5B58;&#x5728;&#x591A;&#x4E2A;&#x6709;&#x6548;&#x7684;&#x82F1;&#x8BED;&#x7FFB;&#x8BD1;&#xFF0C;&#x4F7F;&#x7528;&#x7565;&#x5FAE;&#x4E0D;&#x540C;&#x7684;&#x5355;&#x8BCD;&#x3002;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x6709;&#x4E24;&#x79CD;&#x8BC4;&#x4F30;&#xFF1A;&#x4EBA;&#x5DE5;&#x8BC4;&#x4F30;&#x548C;&#x81EA;&#x52A8;&#x8BC4;&#x4F30;&#x3002;</p>
<p>&#x4EBA;&#x4F53;&#x8BC4;&#x4F30;&#x6D89;&#x53CA;&#x4E00;&#x4E2A;&#x6216;&#x591A;&#x4E2A;&#x4EBA;&#x7C7B;&#x53D7;&#x8BD5;&#x8005;&#xFF0C;&#x8981;&#x4E48;&#x5BF9;&#x6A21;&#x578B;&#x8F93;&#x51FA;&#x7ED9;&#x51FA;&#x201C;&#x7AD6;&#x8D77;&#x62C7;&#x6307;&#x201D;&#x6216;&#x201C;&#x62C7;&#x6307;&#x5411;&#x4E0B;&#x201D;&#x8BC4;&#x7EA7;&#xFF0C;&#x8981;&#x4E48;&#x8FDB;&#x884C;&#x7F16;&#x8F91;&#x4EE5;&#x7EA0;&#x6B63;&#x7FFB;&#x8BD1;&#x3002;&#x8FD9;&#x5BFC;&#x81F4;&#x4E86;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x201C;&#x9519;&#x8BEF;&#x7387;&#x201D;&#xFF0C;&#x5B83;&#x975E;&#x5E38;&#x63A5;&#x8FD1;&#x7CFB;&#x7EDF;&#x8F93;&#x51FA;&#x4E0E;&#x4EBA;&#x5DE5;&#x4EFB;&#x52A1;&#x76F8;&#x5173;&#x7684;&#x6700;&#x7EC8;&#x76EE;&#x6807;&#x3002;&#x4EBA;&#x7C7B;&#x8BC4;&#x4EF7;&#x5F88;&#x91CD;&#x8981;&#xFF0C;&#x4F46;&#x662F;&#x5F88;&#x5C11;&#x4F7F;&#x7528;&#xFF0C;&#x56E0;&#x4E3A;&#x4EBA;&#x7C7B;&#x6CE8;&#x91CA;&#x8005;&#x5F80;&#x5F80;&#x662F;&#x7F13;&#x6162;&#xFF0C;&#x6602;&#x8D35;&#x548C;&#x96BE;&#x4EE5;&#x83B7;&#x5F97;&#x7684;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x4EBA;&#x7C7B;&#x4E5F;&#x53EF;&#x80FD;&#x5F7C;&#x6B64;&#x4E0D;&#x4E00;&#x81F4;&#xFF0C;&#x5E76;&#x4E14;&#xFF0C;&#x4E0E;&#x4EFB;&#x4F55;&#x5176;&#x4ED6;&#x91D1;&#x6807;&#x51C6;&#x4E00;&#x6837;&#xFF0C;&#x4EBA;&#x7C7B;&#x8BC4;&#x4F30;&#x4E0E;&#x6CE8;&#x91CA;&#x5668;&#x95F4;&#x534F;&#x8BAE;&#x7387;&#x914D;&#x5BF9;&#x3002;&#x6D4B;&#x91CF;&#x6CE8;&#x91CA;&#x5668;&#x95F4;&#x534F;&#x8BAE;&#x7387;&#x4E5F;&#x662F;&#x53E6;&#x4E00;&#x4E2A;&#x6602;&#x8D35;&#x7684;&#x4E3B;&#x5F20;&#x3002;&#x4E00;&#x79CD;&#x5E38;&#x89C1;&#x7684;&#x4EBA;&#x7C7B;&#x8BC4;&#x4F30;&#x6307;&#x6807;&#x662F;&#x4EBA;&#x4E3A;&#x76EE;&#x6807;&#x7FFB;&#x8BD1;&#x9519;&#x8BEF;&#x7387;&#xFF08;HTER&#xFF09;&#x3002; HTER&#x662F;&#x4E00;&#x4E2A;&#x52A0;&#x6743;&#x7F16;&#x8F91;&#x8DDD;&#x79BB;&#xFF0C;&#x7531;&#x4EBA;&#x7C7B;&#x4E3A;&#x4E86;&#x5408;&#x7406;&#x5145;&#x5206;&#x7684;&#x610F;&#x4E49;&#x548C;&#x6D41;&#x7545;&#x6027;&#x800C;&#x201C;&#x4FEE;&#x590D;&#x201D;&#x7FFB;&#x8BD1;&#x8F93;&#x51FA;&#x800C;&#x8FDB;&#x884C;&#x7684;&#x63D2;&#x5165;&#xFF0C;&#x5220;&#x9664;&#x548C;&#x8F6C;&#x7F6E;&#x6B21;&#x6570;&#x8BA1;&#x7B97;&#x5F97;&#x51FA;&#xFF08;&#x53C2;&#x89C1;&#x56FE;8-10&#xFF09;&#x3002;</p>
<p><img src="img/388af7f8313976c5e8fb5b223f851953.jpg" alt="Just" title="&#x56FE;8-10\. &#x7FFB;&#x8BD1;&#x4EFB;&#x52A1;&#x7684;&#x4EBA;&#x5DE5;&#x8BC4;&#x4F30;&#x3002;&#xFF08;&#x7531;&#x83F2;&#x5229;&#x666E;&#xB7;&#x79D1;&#x6069;&#xFF09;&#x3002;"> &#x53E6;&#x4E00;&#x65B9;&#x9762;&#xFF0C;&#x81EA;&#x52A8;&#x8BC4;&#x4F30;&#x64CD;&#x4F5C;&#x7B80;&#x5355;&#x5FEB;&#x6377;&#x3002;&#x6709;&#x4E24;&#x79CD;&#x5EA6;&#x91CF;&#x6807;&#x51C6;&#x53EF;&#x7528;&#x4E8E;&#x81EA;&#x52A8;&#x8BC4;&#x4F30;&#x751F;&#x6210;&#x7684;&#x5E8F;&#x5217;&#x3002;&#x6211;&#x4EEC;&#x518D;&#x6B21;&#x4F7F;&#x7528;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x4F5C;&#x4E3A;&#x793A;&#x4F8B;&#xFF0C;&#x4F46;&#x8FD9;&#x4E9B;&#x6307;&#x6807;&#x4E5F;&#x9002;&#x7528;&#x4E8E;&#x6D89;&#x53CA;&#x751F;&#x6210;&#x5E8F;&#x5217;&#x7684;&#x4EFB;&#x4F55;&#x4EFB;&#x52A1;&#x3002;&#x8FD9;&#x4E9B;&#x6307;&#x6807;&#x5305;&#x62EC;&#x57FA;&#x4E8E;ngram&#x91CD;&#x53E0;&#x7684;&#x6307;&#x6807;&#x548C;&#x56F0;&#x60D1;&#x3002;&#x57FA;&#x4E8E;Ngram&#x91CD;&#x53E0;&#x7684;&#x5EA6;&#x91CF;&#x503E;&#x5411;&#x4E8E;&#x901A;&#x8FC7;&#x4F7F;&#x7528;ngram&#x91CD;&#x53E0;&#x7EDF;&#x8BA1;&#x6765;&#x8BA1;&#x7B97;&#x5F97;&#x5206;&#x6765;&#x6D4B;&#x91CF;&#x8F93;&#x51FA;&#x76F8;&#x5BF9;&#x4E8E;&#x53C2;&#x8003;&#x7684;&#x63A5;&#x8FD1;&#x7A0B;&#x5EA6;&#x3002; BLEU&#xFF0C;ROUGE&#x548C;METEOR&#x662F;&#x57FA;&#x4E8E;ngram&#x91CD;&#x53E0;&#x7684;&#x5EA6;&#x91CF;&#x7684;&#x793A;&#x4F8B;&#x3002;&#x5176;&#x4E2D;&#xFF0C;BLEU&#x7ECF;&#x53D7;&#x4E86;&#x65F6;&#x95F4;&#x7684;&#x8003;&#x9A8C;&#xFF0C;&#x6210;&#x4E3A;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x6587;&#x732E;&#x4E2D;&#x7684;&#x8861;&#x91CF;&#x6807;&#x51C6;.6 BLEU&#x4EE3;&#x8868;&#x201C;BiLingual Evaluation Understudy&#x201D;&#x3002;&#x6211;&#x4EEC;&#x8DF3;&#x8FC7;BLEU&#x7684;&#x786E;&#x5207;&#x8868;&#x8FF0;&#xFF0C;&#x5E76;&#x5EFA;&#x8BAE;&#x60A8;&#x9605;&#x8BFB;Papineni&#x7B49;&#x4EBA;&#x3002; &#xFF08;2002&#x5E74;&#xFF09;&#x3002;&#x51FA;&#x4E8E;&#x5B9E;&#x9645;&#x76EE;&#x7684;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x50CF;NLTK7&#x6216;SacreBLEU8&#x8FD9;&#x6837;&#x7684;&#x5305;&#x6765;&#x8BA1;&#x7B97;&#x5206;&#x6570;&#x3002;&#x5F53;&#x53C2;&#x8003;&#x6570;&#x636E;&#x53EF;&#x7528;&#x65F6;&#xFF0C;BLEU&#x672C;&#x8EAB;&#x7684;&#x8BA1;&#x7B97;&#x975E;&#x5E38;&#x5FEB;&#x901F;&#x548C;&#x5BB9;&#x6613;&#x3002;</p>
<p>&#x56F0;&#x60D1;&#x662F;&#x57FA;&#x4E8E;&#x4FE1;&#x606F;&#x7406;&#x8BBA;&#x7684;&#x53E6;&#x4E00;&#x79CD;&#x81EA;&#x52A8;&#x8BC4;&#x4F30;&#x6307;&#x6807;&#xFF0C;&#x60A8;&#x53EF;&#x4EE5;&#x5C06;&#x5176;&#x5E94;&#x7528;&#x4E8E;&#x53EF;&#x4EE5;&#x6D4B;&#x91CF;&#x8F93;&#x51FA;&#x5E8F;&#x5217;&#x6982;&#x7387;&#x7684;&#x4EFB;&#x4F55;&#x60C5;&#x51B5;&#x3002;&#x5BF9;&#x4E8E;&#x5E8F;&#x5217;x&#xFF0C;&#x5982;&#x679C;P&#xFF08;x&#xFF09;&#x662F;&#x5E8F;&#x5217;&#x7684;&#x6982;&#x7387;&#xFF0C;&#x5219;&#x56F0;&#x60D1;&#x5B9A;&#x4E49;&#x5982;&#x4E0B;&#xFF1A;</p>
<p>&#x8FD9;&#x4E3A;&#x6211;&#x4EEC;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x6BD4;&#x8F83;&#x4E0D;&#x540C;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x7684;&#x7B80;&#x5355;&#x65B9;&#x6CD5; - &#x6D4B;&#x91CF;&#x4FDD;&#x6301;&#x6570;&#x636E;&#x96C6;&#x7684;&#x6A21;&#x578B;&#x7684;&#x56F0;&#x60D1;&#x5EA6;&#x3002;&#x867D;&#x7136;&#x8FD9;&#x5F88;&#x5BB9;&#x6613;&#x8BA1;&#x7B97;&#xFF0C;&#x4F46;&#x662F;&#x5F53;&#x7528;&#x4E8E;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x8BC4;&#x4F30;&#x65F6;&#xFF0C;&#x56F0;&#x60D1;&#x4F1A;&#x6709;&#x8BB8;&#x591A;&#x95EE;&#x9898;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x5B83;&#x662F;&#x4E00;&#x4E2A;&#x81A8;&#x80C0;&#x7684;&#x6307;&#x6807;&#x3002;&#x8BF7;&#x6CE8;&#x610F;&#xFF0C;&#x56F0;&#x60D1;&#x7684;&#x8868;&#x8FBE;&#x5F0F;&#x6D89;&#x53CA;&#x53D6;&#x5E42;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x6A21;&#x578B;&#x6027;&#x80FD;&#xFF08;&#x53EF;&#x80FD;&#x6027;&#xFF09;&#x7684;&#x5FAE;&#x5C0F;&#x5DEE;&#x5F02;&#x53EF;&#x80FD;&#x5BFC;&#x81F4;&#x56F0;&#x60D1;&#x7684;&#x5DE8;&#x5927;&#x5DEE;&#x5F02;&#xFF0C;&#x4ECE;&#x800C;&#x4EA7;&#x751F;&#x91CD;&#x5927;&#x8FDB;&#x5C55;&#x7684;&#x9519;&#x89C9;&#x3002;&#x5176;&#x6B21;&#xFF0C;&#x5BF9;&#x56F0;&#x60D1;&#x7684;&#x6539;&#x53D8;&#x53EF;&#x80FD;&#x4E0D;&#x4F1A;&#x8F6C;&#x5316;&#x4E3A;&#x901A;&#x8FC7;&#x5176;&#x4ED6;&#x6307;&#x6807;&#x89C2;&#x5BDF;&#x5230;&#x7684;&#x6A21;&#x578B;&#x9519;&#x8BEF;&#x7387;&#x7684;&#x76F8;&#x5E94;&#x53D8;&#x5316;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x5C31;&#x50CF;BLEU&#x548C;&#x5176;&#x4ED6;&#x57FA;&#x4E8E;ngram&#x7684;&#x6307;&#x6807;&#x4E00;&#x6837;&#xFF0C;&#x56F0;&#x60D1;&#x7684;&#x6539;&#x5584;&#x53EF;&#x80FD;&#x4E0D;&#x4F1A;&#x8F6C;&#x5316;&#x4E3A;&#x4EBA;&#x7C7B;&#x5224;&#x65AD;&#x7684;&#x53EF;&#x5BDF;&#x89C9;&#x7684;&#x6539;&#x8FDB;&#x3002;</p>
<p>&#x5728;&#x4E0B;&#x4E00;&#x8282;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x8DDF;&#x8FDB;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x793A;&#x4F8B;&#xFF0C;&#x5E76;&#x901A;&#x8FC7;PyTorch&#x5B9E;&#x73B0;&#x5C06;&#x8FD9;&#x4E9B;&#x6982;&#x5FF5;&#x5DE7;&#x5999;&#x5730;&#x7ED3;&#x5408;&#x5728;&#x4E00;&#x8D77;&#x3002;</p>
<h2 id="example-neural-machine-translation">Example: Neural Machine Translation</h2>
<p>&#x5728;&#x672C;&#x4F8B;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x4ECB;&#x7ECD;S2S&#x6A21;&#x578B;&#x6700;&#x5E38;&#x7528;&#x7684;&#x5B9E;&#x73B0;:&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x3002;&#x968F;&#x7740;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x5728;2010&#x5E74;&#x4EE3;&#x65E9;&#x671F;&#x7684;&#x6D41;&#x884C;&#xFF0C;&#x5F88;&#x660E;&#x663E;&#xFF0C;&#x4F7F;&#x7528;&#x5D4C;&#x5165;&#x5F0F;&#x8BCD;&#x6C47;&#x548C;RNNs&#x662F;&#x4E00;&#x79CD;&#x975E;&#x5E38;&#x5F3A;&#x5927;&#x7684;&#x4E24;&#x79CD;&#x8BED;&#x8A00;&#x4E4B;&#x95F4;&#x7684;&#x7FFB;&#x8BD1;&#x65B9;&#x6CD5;&#x2014;&#x2014;&#x53EA;&#x8981;&#x6709;&#x8DB3;&#x591F;&#x7684;&#x6570;&#x636E;&#x3002;&#x5F15;&#x5165;&#x201C;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x8BC4;&#x4EF7;&#x201D;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#xFF0C;&#x8FDB;&#x4E00;&#x6B65;&#x5B8C;&#x5584;&#x4E86;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x6A21;&#x578B;&#x3002;&#x5728;&#x8FD9;&#x4E00;&#x90E8;&#x5206;&#xFF0C;&#x6211;&#x4EEC;&#x63CF;&#x8FF0;&#x4E86;&#x4E00;&#x4E2A;&#x57FA;&#x4E8E;Luong, Pham, and Manning(2015)&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x5B83;&#x7B80;&#x5316;&#x4E86;S2S&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x65B9;&#x6CD5;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x9996;&#x5148;&#x6982;&#x8FF0;&#x6570;&#x636E;&#x96C6;&#x548C;&#x795E;&#x7ECF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x6240;&#x9700;&#x7684;&#x7279;&#x6B8A;&#x8BB0;&#x8D26;&#x7C7B;&#x578B;&#x3002;&#x6570;&#x636E;&#x96C6;&#x662F;&#x4E00;&#x4E2A;&#x5E73;&#x884C;&#x7684;&#x8BED;&#x6599;&#x5E93;;&#x5B83;&#x7531;&#x6210;&#x5BF9;&#x7684;&#x82F1;&#x8BED;&#x53E5;&#x5B50;&#x548C;&#x76F8;&#x5E94;&#x7684;&#x6CD5;&#x8BED;&#x7FFB;&#x8BD1;&#x7EC4;&#x6210;&#x3002;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x6B63;&#x5728;&#x5904;&#x7406;&#x4E24;&#x4E2A;&#x53EF;&#x80FD;&#x4E0D;&#x540C;&#x957F;&#x5EA6;&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x8DDF;&#x8E2A;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x548C;&#x8F93;&#x51FA;&#x5E8F;&#x5217;&#x7684;&#x6700;&#x5927;&#x957F;&#x5EA6;&#x548C;&#x8BCD;&#x6C47;&#x3002;&#x5728;&#x5927;&#x591A;&#x6570;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x662F;&#x5BF9;&#x5B8C;&#x6574;&#x8BFB;&#x8005;&#x5728;&#x524D;&#x51E0;&#x7AE0;&#x4E2D;&#x6240;&#x770B;&#x5230;&#x7684;&#x5185;&#x5BB9;&#x7684;&#x76F4;&#x63A5;&#x6269;&#x5C55;&#x3002;</p>
<p>&#x5728;&#x8986;&#x76D6;&#x6570;&#x636E;&#x96C6;&#x548C;&#x7C3F;&#x8BB0;&#x6570;&#x636E;&#x7ED3;&#x6784;&#x4E4B;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x53C2;&#x4E0E;&#x6E90;&#x5E8F;&#x5217;&#x4E2D;&#x7684;&#x4E0D;&#x540C;&#x4F4D;&#x7F6E;&#x6765;&#x904D;&#x5386;&#x6A21;&#x578B;&#x4EE5;&#x53CA;&#x5B83;&#x5982;&#x4F55;&#x751F;&#x6210;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x3002;&#x6211;&#x4EEC;&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x7F16;&#x7801;&#x5668;&#x4F7F;&#x7528;&#x53CC;&#x5411;GRU&#xFF08;bi-GRU&#xFF09;&#x6765;&#x8BA1;&#x7B97;&#x6E90;&#x5E8F;&#x5217;&#x4E2D;&#x6BCF;&#x4E2A;&#x4F4D;&#x7F6E;&#x7684;&#x5411;&#x91CF;&#xFF0C;&#x8FD9;&#x4E9B;&#x5411;&#x91CF;&#x7531;&#x5E8F;&#x5217;&#x7684;&#x6240;&#x6709;&#x90E8;&#x5206;&#x901A;&#x77E5;&#x3002;&#x4E3A;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;PyTorch&#x7684;PackedSequences&#x6570;&#x636E;&#x7ED3;&#x6784;&#x3002;&#x6211;&#x4EEC;&#x5728;&#x201C;NMT&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x7F16;&#x7801;&#x548C;&#x89E3;&#x7801;&#x201D;&#x4E2D;&#x66F4;&#x6DF1;&#x5165;&#x5730;&#x4ECB;&#x7ECD;&#x4E86;&#x8FD9;&#x4E00;&#x70B9;&#x3002;&#x5728;&#x201C;&#x4ECE;&#x5E8F;&#x5217;&#x6355;&#x83B7;&#x66F4;&#x591A;&#xFF1A;&#x6CE8;&#x610F;&#x529B;&#x201D;&#x4E2D;&#x8BA8;&#x8BBA;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x5E94;&#x7528;&#x4E8E;bi-GRU&#x7684;&#x8F93;&#x51FA;&#x5E76;&#x7528;&#x4E8E;&#x8C03;&#x8282;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x3002;&#x6211;&#x4EEC;&#x8BA8;&#x8BBA;&#x6A21;&#x578B;&#x7684;&#x7ED3;&#x679C;&#x4EE5;&#x53CA;&#x5728;&#x201C;&#x8BAD;&#x7EC3;&#x5E38;&#x89C4;&#x548C;&#x7ED3;&#x679C;&#x201D;&#x4E2D;&#x53EF;&#x4EE5;&#x6539;&#x8FDB;&#x7684;&#x65B9;&#x6CD5;&#x3002;</p>
<h3 id="machine-translation-dataset">Machine Translation Dataset</h3>
<p>&#x5BF9;&#x4E8E;&#x6B64;&#x793A;&#x4F8B;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x6765;&#x81EA;Tatoeba Project&#x7684;&#x82F1;&#x8BED; - &#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#x5BF9;&#x7684;&#x6570;&#x636E;&#x96C6;.&#x6570;&#x636E;&#x9884;&#x5904;&#x7406;&#x9996;&#x5148;&#x5C06;&#x6240;&#x6709;&#x53E5;&#x5B50;&#x8BBE;&#x4E3A;&#x5C0F;&#x5199;&#xFF0C;&#x5E76;&#x5C06;NLTK&#x7684;&#x82F1;&#x8BED;&#x548C;&#x6CD5;&#x8BED;&#x6807;&#x8BB0;&#x7B26;&#x5E94;&#x7528;&#x4E8E;&#x6BCF;&#x4E2A;&#x53E5;&#x5B50;&#x5BF9;&#x3002;&#x63A5;&#x4E0B;&#x6765;&#xFF0C;&#x6211;&#x4EEC;&#x5E94;&#x7528;NLTK&#x7684;&#x7279;&#x5B9A;&#x4E8E;&#x8BED;&#x8A00;&#x7684;&#x5355;&#x8BCD;&#x6807;&#x8BB0;&#x751F;&#x6210;&#x5668;&#x6765;&#x521B;&#x5EFA;&#x6807;&#x8BB0;&#x5217;&#x8868;&#x3002;&#x5373;&#x4F7F;&#x6211;&#x4EEC;&#x8FDB;&#x884C;&#x4E86;&#x8FDB;&#x4E00;&#x6B65;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5728;&#x4E0B;&#x4E00;&#x6BB5;&#x4E2D;&#x63CF;&#x8FF0;&#xFF0C;&#x4F46;&#x8FD9;&#x4E2A;&#x6807;&#x8BB0;&#x5217;&#x8868;&#x662F;&#x4E00;&#x4E2A;&#x9884;&#x5904;&#x7406;&#x7684;&#x6570;&#x636E;&#x96C6;&#x3002;</p>
<h2 id="&#x9664;&#x4E86;&#x521A;&#x521A;&#x63CF;&#x8FF0;&#x7684;&#x6807;&#x51C6;&#x9884;&#x5904;&#x7406;&#x4E4B;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684;&#x8BED;&#x6CD5;&#x6A21;&#x5F0F;&#x5217;&#x8868;&#x6765;&#x9009;&#x62E9;&#x6570;&#x636E;&#x7684;&#x5B50;&#x96C6;&#xFF0C;&#x4EE5;&#x7B80;&#x5316;&#x5B66;&#x4E60;&#x95EE;&#x9898;&#x3002;&#x4ECE;&#x672C;&#x8D28;&#x4E0A;&#x8BB2;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x6211;&#x4EEC;&#x5C06;&#x6570;&#x636E;&#x8303;&#x56F4;&#x7F29;&#x5C0F;&#x5230;&#x53EA;&#x6709;&#x6709;&#x9650;&#x8303;&#x56F4;&#x7684;&#x53E5;&#x6CD5;&#x6A21;&#x5F0F;&#x3002;&#x53CD;&#x8FC7;&#x6765;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#xFF0C;&#x6A21;&#x578B;&#x5C06;&#x770B;&#x5230;&#x66F4;&#x5C11;&#x7684;&#x53D8;&#x5316;&#xFF0C;&#x5E76;&#x5728;&#x66F4;&#x77ED;&#x7684;&#x8BAD;&#x7EC3;&#x65F6;&#x95F4;&#x5185;&#x5177;&#x6709;&#x66F4;&#x9AD8;&#x7684;&#x6027;&#x80FD;&#x3002;">&#x9664;&#x4E86;&#x521A;&#x521A;&#x63CF;&#x8FF0;&#x7684;&#x6807;&#x51C6;&#x9884;&#x5904;&#x7406;&#x4E4B;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684;&#x8BED;&#x6CD5;&#x6A21;&#x5F0F;&#x5217;&#x8868;&#x6765;&#x9009;&#x62E9;&#x6570;&#x636E;&#x7684;&#x5B50;&#x96C6;&#xFF0C;&#x4EE5;&#x7B80;&#x5316;&#x5B66;&#x4E60;&#x95EE;&#x9898;&#x3002;&#x4ECE;&#x672C;&#x8D28;&#x4E0A;&#x8BB2;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x6211;&#x4EEC;&#x5C06;&#x6570;&#x636E;&#x8303;&#x56F4;&#x7F29;&#x5C0F;&#x5230;&#x53EA;&#x6709;&#x6709;&#x9650;&#x8303;&#x56F4;&#x7684;&#x53E5;&#x6CD5;&#x6A21;&#x5F0F;&#x3002;&#x53CD;&#x8FC7;&#x6765;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#xFF0C;&#x6A21;&#x578B;&#x5C06;&#x770B;&#x5230;&#x66F4;&#x5C11;&#x7684;&#x53D8;&#x5316;&#xFF0C;&#x5E76;&#x5728;&#x66F4;&#x77ED;&#x7684;&#x8BAD;&#x7EC3;&#x65F6;&#x95F4;&#x5185;&#x5177;&#x6709;&#x66F4;&#x9AD8;&#x7684;&#x6027;&#x80FD;&#x3002;</h2>
<p>Note</p>
<h2 id="&#x5728;&#x6784;&#x5EFA;&#x65B0;&#x6A21;&#x578B;&#x548C;&#x5C1D;&#x8BD5;&#x65B0;&#x4F53;&#x7CFB;&#x7ED3;&#x6784;&#x65F6;&#xFF0C;&#x60A8;&#x5E94;&#x8BE5;&#x5728;&#x5EFA;&#x6A21;&#x9009;&#x62E9;&#x548C;&#x8BC4;&#x4F30;&#x8FD9;&#x4E9B;&#x9009;&#x62E9;&#x4E4B;&#x95F4;&#x5B9E;&#x73B0;&#x66F4;&#x5FEB;&#x7684;&#x8FED;&#x4EE3;&#x5468;&#x671F;&#x3002;">&#x5728;&#x6784;&#x5EFA;&#x65B0;&#x6A21;&#x578B;&#x548C;&#x5C1D;&#x8BD5;&#x65B0;&#x4F53;&#x7CFB;&#x7ED3;&#x6784;&#x65F6;&#xFF0C;&#x60A8;&#x5E94;&#x8BE5;&#x5728;&#x5EFA;&#x6A21;&#x9009;&#x62E9;&#x548C;&#x8BC4;&#x4F30;&#x8FD9;&#x4E9B;&#x9009;&#x62E9;&#x4E4B;&#x95F4;&#x5B9E;&#x73B0;&#x66F4;&#x5FEB;&#x7684;&#x8FED;&#x4EE3;&#x5468;&#x671F;&#x3002;</h2>
<p>&#x6211;&#x4EEC;&#x7528;&#x6765;&#x9009;&#x62E9;&#x6570;&#x636E;&#x5B50;&#x96C6;&#x7684;&#x53E5;&#x6CD5;&#x6A21;&#x5F0F;&#x662F;&#x4EE5;&#x201C;I am&#x201D;&#xFF0C;&#x201C;he is &#x201D;&#xFF0C;&#x201C;she is&#x201D;&#xFF0C;&#x201C;they are&#x201D;&#xFF0C;&#x201C;you are&#x201D;&#x6216;&#x201C;we are&#x201D;&#x5F00;&#x5934;&#x7684;&#x82F1;&#x8BED;&#x53E5;&#x5B50;&#x3002;&#x6570;&#x636E;&#x96C6;&#x4ECE;135,842&#x4E2A;&#x53E5;&#x5B50;&#x5BF9;&#x51CF;&#x5C11;&#x5230;13,062&#x4E2A;&#x53E5;&#x5B50;&#x5BF9;&#xFF0C;&#x7CFB;&#x6570;&#x4E3A;10.&#x4E3A;&#x4E86;&#x6700;&#x7EC8;&#x786E;&#x5B9A;&#x5B66;&#x4E60;&#x8BBE;&#x7F6E;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5269;&#x4F59;&#x7684;13,062&#x4E2A;&#x53E5;&#x5B50;&#x5BF9;&#x5206;&#x4E3A;70&#xFF05;&#x8BAD;&#x7EC3;&#xFF0C;15&#xFF05;&#x9A8C;&#x8BC1;&#x548C;15&#xFF05;&#x6D4B;&#x8BD5;&#x5206;&#x88C2;&#x3002;&#x4ECE;&#x521A;&#x521A;&#x5217;&#x51FA;&#x7684;&#x8BED;&#x6CD5;&#x5F00;&#x59CB;&#x7684;&#x6BCF;&#x4E2A;&#x53E5;&#x5B50;&#x7684;&#x6BD4;&#x4F8B;&#x901A;&#x8FC7;&#x9996;&#x5148;&#x6309;&#x53E5;&#x5B50;&#x5F00;&#x59CB;&#x5206;&#x7EC4;&#xFF0C;&#x4ECE;&#x8FD9;&#x4E9B;&#x7EC4;&#x521B;&#x5EFA;&#x5206;&#x5272;&#xFF0C;&#x7136;&#x540E;&#x5408;&#x5E76;&#x6BCF;&#x4E2A;&#x7EC4;&#x7684;&#x5206;&#x5272;&#x6765;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;&#x3002;</p>
<h3 id="a-vectorization-pipeline-for-nmt">A Vectorization Pipeline for NMT</h3>
<p>&#x5BF9;&#x6E90;&#x82F1;&#x8BED;&#x548C;&#x76EE;&#x6807;&#x6CD5;&#x8BED;&#x53E5;&#x5B50;&#x8FDB;&#x884C;&#x77E2;&#x91CF;&#x5316;&#x9700;&#x8981;&#x6BD4;&#x524D;&#x9762;&#x7AE0;&#x8282;&#x4E2D;&#x770B;&#x5230;&#x7684;&#x66F4;&#x590D;&#x6742;&#x7684;&#x7BA1;&#x9053;&#x3002;&#x590D;&#x6742;&#x6027;&#x589E;&#x52A0;&#x6709;&#x4E24;&#x4E2A;&#x539F;&#x56E0;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x6E90;&#x5E8F;&#x5217;&#x548C;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x5728;&#x6A21;&#x578B;&#x4E2D;&#x5177;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x89D2;&#x8272;&#xFF0C;&#x5C5E;&#x4E8E;&#x4E0D;&#x540C;&#x7684;&#x8BED;&#x8A00;&#xFF0C;&#x5E76;&#x4E14;&#x4EE5;&#x4E24;&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x65B9;&#x5F0F;&#x8FDB;&#x884C;&#x77E2;&#x91CF;&#x5316;&#x3002;&#x5176;&#x6B21;&#xFF0C;&#x4F5C;&#x4E3A;&#x4F7F;&#x7528;PyTorch&#x7684;PackedSequences&#x7684;&#x5148;&#x51B3;&#x6761;&#x4EF6;&#xFF0C;&#x6211;&#x4EEC;&#x6309;&#x6E90;&#x53E5;&#x7684;&#x957F;&#x5EA6;&#x5BF9;&#x6BCF;&#x4E2A;&#x5C0F;&#x6279;&#x91CF;&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#x3002;&#x4E3A;&#x4E86;&#x51C6;&#x5907;&#x8FD9;&#x4E24;&#x4E2A;&#x590D;&#x6742;&#x6027;&#xFF0C;NMTVectorizer&#x5B9E;&#x4F8B;&#x5316;&#x4E86;&#x4E24;&#x4E2A;&#x72EC;&#x7ACB;&#x7684;SequenceVocabulary&#x5BF9;&#x8C61;&#x548C;&#x4E24;&#x4E2A;&#x6700;&#x5927;&#x5E8F;&#x5217;&#x957F;&#x5EA6;&#x7684;&#x6D4B;&#x91CF;&#xFF0C;&#x5982;&#x4F8B;8-1&#x6240;&#x793A;&#x3002; Example 8-1. Constructing the NMTVectorizer</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTVectorizer</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, source_vocab, target_vocab, max_source_length,
                 max_target_length)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Args:
            source_vocab (SequenceVocabulary): maps source words to integers
            target_vocab (SequenceVocabulary): maps target words to integers
            max_source_length (int): the longest sequence in the source dataset
            max_target_length (int): the longest sequence in the target dataset
        &quot;&quot;&quot;</span>
        self.source_vocab = source_vocab
        self.target_vocab = target_vocab

        self.max_source_length = max_source_length
        self.max_target_length = max_target_length

<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_dataframe</span><span class="hljs-params">(cls, bitext_df)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Instantiate the vectorizer from the dataset dataframe

        Args:
            bitext_df (pandas.DataFrame): the parallel text dataset
        Returns:
            an instance of the NMTVectorizer
        &quot;&quot;&quot;</span>
        source_vocab = SequenceVocabulary()
        target_vocab = SequenceVocabulary()
        max_source_length, max_target_length = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>

        <span class="hljs-keyword">for</span> _, row <span class="hljs-keyword">in</span> bitext_df.iterrows():
            source_tokens = row[<span class="hljs-string">&quot;source_language&quot;</span>].split(<span class="hljs-string">&quot; &quot;</span>)
            <span class="hljs-keyword">if</span> len(source_tokens) &gt; max_source_length:
                max_source_length = len(source_tokens)
            <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> source_tokens:
                source_vocab.add_token(token)

            target_tokens = row[<span class="hljs-string">&quot;target_language&quot;</span>].split(<span class="hljs-string">&quot; &quot;</span>)
            <span class="hljs-keyword">if</span> len(target_tokens) &gt; max_target_length:
                max_target_length = len(target_tokens)
            <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> target_tokens:
                target_vocab.add_token(token)

        <span class="hljs-keyword">return</span> cls(source_vocab, target_vocab, max_source_length,
                   max_target_length
</code></pre>
<p>&#x590D;&#x6742;&#x6027;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x589E;&#x52A0;&#x662F;&#x5904;&#x7406;&#x6E90;&#x5E8F;&#x5217;&#x548C;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x7684;&#x4E0D;&#x540C;&#x65B9;&#x5F0F;&#x3002;&#x6E90;&#x5E8F;&#x5217;&#x5728;&#x5F00;&#x59CB;&#x65F6;&#x63D2;&#x5165;BEGIN-OF-SEQUENCE&#x8FDB;&#x884C;&#x77E2;&#x91CF;&#x5316;&#xFF0C;&#x5E76;&#x5C06;END-OF-SEQUENCE&#x6807;&#x8BB0;&#x6DFB;&#x52A0;&#x5230;&#x7ED3;&#x5C3E;&#x3002;&#x8BE5;&#x6A21;&#x578B;&#x4F7F;&#x7528;bi-GRU&#x4E3A;&#x6E90;&#x53E5;&#x5B50;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x6807;&#x8BB0;&#x521B;&#x5EFA;&#x6458;&#x8981;&#x5411;&#x91CF;&#xFF0C;&#x5E76;&#x4E14;&#x8FD9;&#x4E9B;&#x6458;&#x8981;&#x5411;&#x91CF;&#x6781;&#x5927;&#x5730;&#x53D7;&#x76CA;&#x4E8E;&#x5177;&#x6709;&#x53E5;&#x5B50;&#x8FB9;&#x754C;&#x7684;&#x6307;&#x793A;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x88AB;&#x77E2;&#x91CF;&#x5316;&#x4E3A;&#x4E24;&#x4E2A;&#x526F;&#x672C;&#xFF0C;&#x504F;&#x79FB;&#x4E00;&#x4E2A;&#x6807;&#x8BB0;&#xFF1A;&#x7B2C;&#x4E00;&#x4E2A;&#x526F;&#x672C;&#x9700;&#x8981;BEGIN-OF-SEQUENCE&#x6807;&#x8BB0;&#xFF0C;&#x7B2C;&#x4E8C;&#x4E2A;&#x526F;&#x672C;&#x9700;&#x8981;END-OF-SEQUENCE&#x6807;&#x8BB0;&#x3002;&#x5982;&#x679C;&#x60A8;&#x4ECE;&#x7B2C;7&#x7AE0;&#x56DE;&#x5FC6;&#x8D77;&#x6765;&#xFF0C;&#x5E8F;&#x5217;&#x9884;&#x6D4B;&#x4EFB;&#x52A1;&#x9700;&#x8981;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x89C2;&#x5BDF;&#x8F93;&#x5165;&#x4EE4;&#x724C;&#x548C;&#x8F93;&#x51FA;&#x4EE4;&#x724C;&#x3002; S2S&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x89E3;&#x7801;&#x5668;&#x6B63;&#x5728;&#x6267;&#x884C;&#x6B64;&#x4EFB;&#x52A1;&#xFF0C;&#x4F46;&#x589E;&#x52A0;&#x4E86;&#x7F16;&#x7801;&#x5668;&#x4E0A;&#x4E0B;&#x6587;&#x7684;&#x53EF;&#x7528;&#x6027;&#x3002;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x8FD9;&#x79CD;&#x590D;&#x6742;&#x6027;&#xFF0C;&#x6211;&#x4EEC;&#x5236;&#x5B9A;&#x4E86;&#x6838;&#x5FC3;&#x77E2;&#x91CF;&#x5316;&#x65B9;&#x6CD5;_vectorize&#xFF0C;&#x65E0;&#x8BBA;&#x5B83;&#x662F;&#x6E90;&#x7D22;&#x5F15;&#x8FD8;&#x662F;&#x76EE;&#x6807;&#x7D22;&#x5F15;&#x90FD;&#x65E0;&#x5173;&#x7D27;&#x8981;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x7F16;&#x5199;&#x4E24;&#x4E2A;&#x65B9;&#x6CD5;&#x6765;&#x5206;&#x522B;&#x5904;&#x7406;&#x6E90;&#x7D22;&#x5F15;&#x548C;&#x76EE;&#x6807;&#x7D22;&#x5F15;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x4F7F;&#x7528;NMTVectorizer.vectorize&#x65B9;&#x6CD5;&#x534F;&#x8C03;&#x8FD9;&#x4E9B;&#x7D22;&#x5F15;&#x96C6;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x662F;&#x6570;&#x636E;&#x96C6;&#x8C03;&#x7528;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x4F8B;8-2&#x663E;&#x793A;&#x4E86;&#x4EE3;&#x7801;&#x3002;</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTVectorizer</span><span class="hljs-params">(object)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_vectorize</span><span class="hljs-params">(self, indices, vector_length=<span class="hljs-number">-1</span>, mask_index=<span class="hljs-number">0</span>)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Vectorize the provided indices

        Args:
            indices (list): a list of integers that represent a sequence
            vector_length (int): an argument for forcing the length of index vector
            mask_index (int): the mask_index to use; almost always 0
        &quot;&quot;&quot;</span>
        <span class="hljs-keyword">if</span> vector_length &lt; <span class="hljs-number">0</span>:
            vector_length = len(indices)
        vector = np.zeros(vector_length, dtype=np.int64)
        vector[:len(indices)] = indices
        vector[len(indices):] = mask_index
        <span class="hljs-keyword">return</span> vector

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_source_indices</span><span class="hljs-params">(self, text)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Return the vectorized source text

        Args:
            text (str): the source text; tokens should be separated by spaces
        Returns:
            indices (list): list of integers representing the text
        &quot;&quot;&quot;</span>
        indices = [self.source_vocab.begin_seq_index]
        indices.extend(self.source_vocab.lookup_token(token)
                       <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> text.split(<span class="hljs-string">&quot; &quot;</span>))
        indices.append(self.source_vocab.end_seq_index)
        <span class="hljs-keyword">return</span> indices

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_target_indices</span><span class="hljs-params">(self, text)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Return the vectorized source text

        Args:
            text (str): the source text; tokens should be separated by spaces
        Returns:
            a tuple: (x_indices, y_indices)
                x_indices (list): list of ints; observations in target decoder
                y_indices (list): list of ints; predictions in target decoder
        &quot;&quot;&quot;</span>
        indices = [self.target_vocab.lookup_token(token)
                   <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> text.split(<span class="hljs-string">&quot; &quot;</span>)]
        x_indices = [self.target_vocab.begin_seq_index] + indices
        y_indices = indices + [self.target_vocab.end_seq_index]
        <span class="hljs-keyword">return</span> x_indices, y_indices

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">vectorize</span><span class="hljs-params">(self, source_text, target_text, use_dataset_max_lengths=True)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;Return the vectorized source and target text

        Args:
            source_text (str): text from the source language
            target_text (str): text from the target language
            use_dataset_max_lengths (bool): whether to use the max vector lengths
        Returns:
            The vectorized data point as a dictionary with the keys:
                source_vector, target_x_vector, target_y_vector, source_length
        &quot;&quot;&quot;</span>
        source_vector_length = <span class="hljs-number">-1</span>
        target_vector_length = <span class="hljs-number">-1</span>

        <span class="hljs-keyword">if</span> use_dataset_max_lengths:
            source_vector_length = self.max_source_length + <span class="hljs-number">2</span>
            target_vector_length = self.max_target_length + <span class="hljs-number">1</span>

        source_indices = self._get_source_indices(source_text)
        source_vector = self._vectorize(source_indices,
                                        vector_length=source_vector_length,
                                        mask_index=self.source_vocab.mask_index)

        target_x_indices, target_y_indices = self._get_target_indices(target_text)
        target_x_vector = self._vectorize(target_x_indices,
                                        vector_length=target_vector_length,
                                        mask_index=self.target_vocab.mask_index)
        target_y_vector = self._vectorize(target_y_indices,
                                        vector_length=target_vector_length,
                                        mask_index=self.target_vocab.mask_index)
        <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;source_vector&quot;</span>: source_vector,
                <span class="hljs-string">&quot;target_x_vector&quot;</span>: target_x_vector,
                <span class="hljs-string">&quot;target_y_vector&quot;</span>: target_y_vector,
                <span class="hljs-string">&quot;source_length&quot;</span>: len(source_indices)}
</code></pre>
<p>&#x590D;&#x6742;&#x6027;&#x7684;&#x7B2C;&#x4E8C;&#x6B21;&#x589E;&#x52A0;&#x518D;&#x6B21;&#x6765;&#x81EA;&#x6E90;&#x5E8F;&#x5217;&#x3002;&#x4E3A;&#x4E86;&#x4F7F;&#x7528;bi-GRU&#x5BF9;&#x6E90;&#x5E8F;&#x5217;&#x8FDB;&#x884C;&#x7F16;&#x7801;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;PyTorch&#x7684;PackedSequences&#x6570;&#x636E;&#x7ED3;&#x6784;&#x3002;&#x901A;&#x5E38;&#xFF0C;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x7684;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x5B57;&#x8868;&#x793A;&#x4E3A;&#x6574;&#x6570;&#x77E9;&#x9635;&#x4E2D;&#x7684;&#x884C;&#xFF0C;&#x5176;&#x4E2D;&#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x5DE6;&#x5BF9;&#x9F50;&#x5E76;&#x4E14;&#x96F6;&#x586B;&#x5145;&#x4EE5;&#x9002;&#x5E94;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x3002; PackedSequences&#x6570;&#x636E;&#x7ED3;&#x6784;&#x901A;&#x8FC7;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#xFF0C;&#x4E00;&#x4E2A;&#x63A5;&#x4E00;&#x4E2A;&#x5730;&#x8FDE;&#x63A5;&#x5E8F;&#x5217;&#x7684;&#x6570;&#x636E;&#x5E76;&#x77E5;&#x9053;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x7684;&#x5E8F;&#x5217;&#x6570;&#xFF0C;&#x5C06;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x8868;&#x793A;&#x4E3A;&#x6570;&#x7EC4;&#xFF0C;&#x5982;&#x56FE;8-11&#x6240;&#x793A;&#x3002;</p>
<p><img src="img/6ed27ac12afc752f06af3ce102e33503.jpg" alt="example5" title="&#x56FE;8-11&#x3002;&#x586B;&#x5145;&#x5E8F;&#x5217;&#x77E9;&#x9635;&#x53CA;&#x5176;&#x957F;&#x5EA6;&#x663E;&#x793A;&#x5728;&#x5DE6;&#x4FA7;&#x3002;&#x586B;&#x5145;&#x77E9;&#x9635;&#x662F;&#x901A;&#x8FC7;&#x7528;0&#xFF08;&#x96F6;&#xFF09;&#x5BF9;&#x5B83;&#x4EEC;&#x8FDB;&#x884C;&#x53F3;&#x8FB9;&#x586B;&#x5145;&#x5E76;&#x5C06;&#x5B83;&#x4EEC;&#x5806;&#x53E0;&#x4E3A;&#x884C;&#x5411;&#x91CF;&#x6765;&#x8868;&#x793A;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x7684;&#x6807;&#x51C6;&#x65B9;&#x5F0F;&#x3002;&#x5728;PyTorch&#x8BED;&#x4E49;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5C06;&#x586B;&#x5145;&#x5E8F;&#x5217;&#x6253;&#x5305;&#x6210;&#x4E00;&#x4E2A;terser&#x8868;&#x793A;&#xFF0C;Packed Sequences&#xFF0C;&#x53F3;&#x4FA7;&#x663E;&#x793A;batch_sizes&#x3002;&#x8BE5;&#x8868;&#x793A;&#x5141;&#x8BB8;GPU&#x901A;&#x8FC7;&#x8DDF;&#x8E2A;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x4E2D;&#x6709;&#x591A;&#x5C11;&#x5E8F;&#x5217;&#xFF08;batch_sizes&#xFF09;&#x6765;&#x9010;&#x6B65;&#x6267;&#x884C;&#x5E8F;&#x5217;&#x3002;"></p>
<p>&#x521B;&#x5EFA;PackedSequence&#x6709;&#x4E24;&#x4E2A;&#x5148;&#x51B3;&#x6761;&#x4EF6;&#xFF1A;&#x4E86;&#x89E3;&#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#xFF0C;&#x5E76;&#x6309;&#x6E90;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#x6309;&#x964D;&#x5E8F;&#x5BF9;&#x5E8F;&#x5217;&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#x3002;&#x4E3A;&#x4E86;&#x53CD;&#x6620;&#x8FD9;&#x4E2A;&#x65B0;&#x6392;&#x5E8F;&#x7684;&#x77E9;&#x9635;&#xFF0C;&#x5C0F;&#x6279;&#x91CF;&#x4E2D;&#x7684;&#x5269;&#x4F59;&#x5F20;&#x91CF;&#x6309;&#x76F8;&#x540C;&#x7684;&#x987A;&#x5E8F;&#x6392;&#x5E8F;&#xFF0C;&#x4EE5;&#x4FBF;&#x5B83;&#x4EEC;&#x4E0E;&#x6E90;&#x5E8F;&#x5217;&#x7F16;&#x7801;&#x4FDD;&#x6301;&#x4E00;&#x81F4;&#x3002;&#x5728;&#x4F8B;8-3&#x4E2D;&#xFF0C;generate_batches&#x51FD;&#x6570;&#x88AB;&#x4FEE;&#x6539;&#x4E3A;generate_nmt_batches&#x51FD;&#x6570;&#x3002;</p>
<p>Example 8-3. Generating minibatches for the NMT example</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generate_nmt_batches</span><span class="hljs-params">(dataset, batch_size, shuffle=True,
                            drop_last=True, device=<span class="hljs-string">&quot;cpu&quot;</span>)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;A generator function which wraps the PyTorch DataLoader; NMT Version &quot;&quot;&quot;</span>
    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,
                            shuffle=shuffle, drop_last=drop_last)

    <span class="hljs-keyword">for</span> data_dict <span class="hljs-keyword">in</span> dataloader:
        lengths = data_dict[<span class="hljs-string">&apos;x_source_length&apos;</span>].numpy()
        sorted_length_indices = lengths.argsort()[::<span class="hljs-number">-1</span>].tolist()

        out_data_dict = {}
        <span class="hljs-keyword">for</span> name, tensor <span class="hljs-keyword">in</span> data_dict.items():
            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)
        <span class="hljs-keyword">yield</span> out_data_dict
</code></pre>
<h3 id="encoding-and-decoding-in-the-nmt-model">Encoding and Decoding in the NMT Model</h3>
<p>&#x5728;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x4ECE;&#x6E90;&#x5E8F;&#x5217;&#x5F00;&#x59CB; - &#x4E00;&#x4E2A;&#x82F1;&#x8BED;&#x53E5;&#x5B50; - &#x6211;&#x4EEC;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x76EE;&#x6807;&#x5E8F;&#x5217; - &#x76F8;&#x5E94;&#x7684;&#x6CD5;&#x8BED;&#x7FFB;&#x8BD1;&#x3002;&#x6807;&#x51C6;&#x65B9;&#x6CD5;&#x662F;&#x4F7F;&#x7528;&#x201C;&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#xFF0C;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x548C;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x201D;&#x4E2D;&#x63CF;&#x8FF0;&#x7684;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x3002;&#x5728;&#x793A;&#x4F8B;8-4&#x548C;&#x793A;&#x4F8B;8-5&#x4E2D;&#x5448;&#x73B0;&#x7684;&#x6A21;&#x578B;&#x4E2D;&#xFF0C;&#x7F16;&#x7801;&#x5668;&#x9996;&#x5148;&#x5C06;&#x6BCF;&#x4E2A;&#x6E90;&#x5E8F;&#x5217;&#x6620;&#x5C04;&#x5230;&#x5177;&#x6709;bi-GRU&#x7684;&#x77E2;&#x91CF;&#x72B6;&#x6001;&#x5E8F;&#x5217;&#xFF08;&#x53C2;&#x89C1;&#x201C;&#x4ECE;&#x5E8F;&#x5217;&#x4E2D;&#x6355;&#x83B7;&#x66F4;&#x591A;&#xFF1A;&#x53CC;&#x5411;&#x9012;&#x5F52;&#x6A21;&#x578B;&#x201D;&#xFF09;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x89E3;&#x7801;&#x5668;&#x4EE5;&#x89E3;&#x7801;&#x5668;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4F5C;&#x4E3A;&#x5176;&#x521D;&#x59CB;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x5F00;&#x59CB;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;&#x6CE8;&#x610F;&#x673A;&#x5236;&#xFF08;&#x53C2;&#x89C1;&#x201C;&#x4ECE;&#x5E8F;&#x5217;&#x4E2D;&#x6355;&#x83B7;&#x66F4;&#x591A;&#xFF1A;&#x6CE8;&#x610F;&#x201D;&#xFF09;&#x6765;&#x9009;&#x62E9;&#x6E90;&#x5E8F;&#x5217;&#x4E2D;&#x7684;&#x4E0D;&#x540C;&#x4FE1;&#x606F;&#x4EE5;&#x751F;&#x6210;&#x8F93;&#x51FA;&#x5E8F;&#x5217;&#x3002;&#x5728;&#x672C;&#x8282;&#x7684;&#x5176;&#x4F59;&#x90E8;&#x5206;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x66F4;&#x8BE6;&#x7EC6;&#x5730;&#x89E3;&#x91CA;&#x6B64;&#x8FC7;&#x7A0B;&#x3002;</p>
<p>Example 8-4. The NMTModel encapsulates and coordinates the encoder and decoder in a single forward method.</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTModel</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot; A Neural Machine Translation Model &quot;&quot;&quot;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, source_vocab_size, source_embedding_size,
                 target_vocab_size, target_embedding_size, encoding_size,
                 target_bos_index)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Args:
            source_vocab_size (int): number of unique words in source language
            source_embedding_size (int): size of the source embedding vectors
            target_vocab_size (int): number of unique words in target language
            target_embedding_size (int): size of the target embedding vectors
            encoding_size (int): the size of the encoder RNN.
            target_bos_index (int): index for BEGIN-OF-SEQUENCE token
        &quot;&quot;&quot;</span>
        super(NMTModel, self).__init__()
        self.encoder = NMTEncoder(num_embeddings=source_vocab_size,
                                  embedding_size=source_embedding_size,
                                  rnn_hidden_size=encoding_size)
        decoding_size = encoding_size * <span class="hljs-number">2</span>
        self.decoder = NMTDecoder(num_embeddings=target_vocab_size,
                                  embedding_size=target_embedding_size,
                                  rnn_hidden_size=decoding_size,
                                  bos_index=target_bos_index)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x_source, x_source_lengths, target_sequence)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;The forward pass of the model

        Args:
            x_source (torch.Tensor): the source text data tensor.
                x_source.shape should be (batch, vectorizer.max_source_length)
            x_source_lengths torch.Tensor): the length of the sequences in x_source
            target_sequence (torch.Tensor): the target text data tensor
        Returns:
            decoded_states (torch.Tensor): prediction vectors at each output step
        &quot;&quot;&quot;</span>
        encoder_state, final_hidden_states = self.encoder(x_source,
                                                          x_source_lengths)
        decoded_states = self.decoder(encoder_state=encoder_state,
                                      initial_hidden_state=final_hidden_states,
                                      target_sequence=target_sequence)
        <span class="hljs-keyword">return</span> decoded_states
</code></pre>
<p>THE ENCODER Example 8-5. The encoder embeds the source words and extracts features with a bi-GRU</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTEncoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_embeddings, embedding_size, rnn_hidden_size)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Args:
            num_embeddings (int): size of source vocabulary
            embedding_size (int): size of the embedding vectors
            rnn_hidden_size (int): size of the RNN hidden state vectors
        &quot;&quot;&quot;</span>
        super(NMTEncoder, self).__init__()

        self.source_embedding = nn.Embedding(num_embeddings, embedding_size,
                                             padding_idx=<span class="hljs-number">0</span>)
        self.birnn = nn.GRU(embedding_size, rnn_hidden_size, bidirectional=<span class="hljs-keyword">True</span>,
                            batch_first=<span class="hljs-keyword">True</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x_source, x_lengths)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;The forward pass of the model

        Args:
            x_source (torch.Tensor): the input data tensor.
                x_source.shape is (batch, seq_size)
            x_lengths (torch.Tensor): vector of lengths for each item in the batch
        Returns:
            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)
                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)
                x_birnn_h.shape = (batch, rnn_hidden_size * 2)
        &quot;&quot;&quot;</span>
        x_embedded = self.source_embedding(x_source)
        <span class="hljs-comment"># create PackedSequence; x_packed.data.shape=(number_items, embedding_size)</span>
        x_lengths = x_lengths.detach().cpu().numpy()
        x_packed = pack_padded_sequence(x_embedded, x_lengths, batch_first=<span class="hljs-keyword">True</span>)

        <span class="hljs-comment"># x_birnn_h.shape = (num_rnn, batch_size, feature_size)</span>
        x_birnn_out, x_birnn_h  = self.birnn(x_packed)
        <span class="hljs-comment"># permute to (batch_size, num_rnn, feature_size)</span>
        x_birnn_h = x_birnn_h.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)

        <span class="hljs-comment"># flatten features; reshape to (batch_size, num_rnn * feature_size)</span>
        <span class="hljs-comment">#  (recall: -1 takes the remaining positions,</span>
        <span class="hljs-comment">#           flattening the two RNN hidden vectors into 1)</span>
        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)

        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=<span class="hljs-keyword">True</span>)
        <span class="hljs-keyword">return</span> x_unpacked, x_birnn_h
</code></pre>
<p>&#x901A;&#x5E38;&#xFF0C;&#x7F16;&#x7801;&#x5668;&#x5C06;&#x6574;&#x6570;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x5E76;&#x4E3A;&#x6BCF;&#x4E2A;&#x4F4D;&#x7F6E;&#x521B;&#x5EFA;&#x7279;&#x5F81;&#x5411;&#x91CF;&#x3002;&#x5728;&#x8BE5;&#x793A;&#x4F8B;&#x4E2D;&#xFF0C;&#x7F16;&#x7801;&#x5668;&#x7684;&#x8F93;&#x51FA;&#x662F;&#x8FD9;&#x4E9B;&#x5411;&#x91CF;&#x4EE5;&#x53CA;&#x7528;&#x4E8E;&#x5236;&#x4F5C;&#x7279;&#x5F81;&#x5411;&#x91CF;&#x7684;bi-GRU&#x7684;&#x6700;&#x7EC8;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x3002;&#x8BE5;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x7528;&#x4E8E;&#x5728;&#x4E0B;&#x4E00;&#x8282;&#x4E2D;&#x521D;&#x59CB;&#x5316;&#x89E3;&#x7801;&#x5668;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x3002;</p>
<p>&#x6DF1;&#x5165;&#x4E86;&#x89E3;&#x7F16;&#x7801;&#x5668;&#xFF0C;&#x6211;&#x4EEC;&#x9996;&#x5148;&#x4F7F;&#x7528;&#x5D4C;&#x5165;&#x5C42;&#x5D4C;&#x5165;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x3002;&#x901A;&#x5E38;&#xFF0C;&#x53EA;&#x9700;&#x5728;&#x5D4C;&#x5165;&#x5C42;&#x4E0A;&#x8BBE;&#x7F6E;padding_idx&#x6807;&#x5FD7;&#xFF0C;&#x6211;&#x4EEC;&#x5C31;&#x53EF;&#x4EE5;&#x4F7F;&#x6A21;&#x578B;&#x5904;&#x7406;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#xFF0C;&#x56E0;&#x4E3A;&#x4EFB;&#x4F55;&#x7B49;&#x4E8E;padding_idx&#x7684;&#x4F4D;&#x7F6E;&#x90FD;&#x4F1A;&#x88AB;&#x8D4B;&#x4E88;&#x96F6;&#x503C;&#x5411;&#x91CF;&#xFF0C;&#x8BE5;&#x5411;&#x91CF;&#x5728;&#x4F18;&#x5316;&#x671F;&#x95F4;&#x4E0D;&#x4F1A;&#x66F4;&#x65B0;&#x3002;&#x56DE;&#x60F3;&#x4E00;&#x4E0B;&#xFF0C;&#x8FD9;&#x88AB;&#x79F0;&#x4E3A;&#x9762;&#x5177;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x5728;&#x8FD9;&#x79CD;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x4E2D;&#xFF0C;&#x63A9;&#x853D;&#x4F4D;&#x7F6E;&#x9700;&#x8981;&#x4EE5;&#x4E0D;&#x540C;&#x65B9;&#x5F0F;&#x5904;&#x7406;&#xFF0C;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x4F7F;&#x7528;bi-GRU&#x6765;&#x7F16;&#x7801;&#x6E90;&#x5E8F;&#x5217;&#x3002;&#x4E3B;&#x8981;&#x539F;&#x56E0;&#x662F;&#x540E;&#x5411;&#x5206;&#x91CF;&#x53EF;&#x80FD;&#x53D7;&#x5230;&#x5C4F;&#x853D;&#x4F4D;&#x7F6E;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x5176;&#x56E0;&#x5B50;&#x4E0E;&#x5728;&#x5E8F;&#x5217;&#x4E0A;&#x5F00;&#x59CB;&#x4E4B;&#x524D;&#x9047;&#x5230;&#x7684;&#x5C4F;&#x853D;&#x4F4D;&#x7F6E;&#x7684;&#x6570;&#x91CF;&#x6210;&#x6BD4;&#x4F8B;&#x3002;</p>
<p>&#x4E3A;&#x4E86;&#x5904;&#x7406;bi-GRU&#x4E2D;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x7684;&#x63A9;&#x7801;&#x4F4D;&#x7F6E;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;PyTorch&#x7684;PackedSequence&#x6570;&#x636E;&#x7ED3;&#x6784;&#x3002; PackedSequences&#x6E90;&#x81EA;CUDA&#x5982;&#x4F55;&#x5141;&#x8BB8;&#x4EE5;&#x6279;&#x5904;&#x7406;&#x683C;&#x5F0F;&#x5904;&#x7406;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x3002;&#x5982;&#x679C;&#x6EE1;&#x8DB3;&#x4E24;&#x4E2A;&#x6761;&#x4EF6;&#xFF0C;&#x5219;&#x53EF;&#x4EE5;&#x5C06;&#x4EFB;&#x4F55;&#x96F6;&#x586B;&#x5145;&#x5E8F;&#x5217;&#xFF08;&#x4F8B;&#x5982;&#x793A;&#x4F8B;8-6&#x4E2D;&#x6240;&#x793A;&#x7684;&#x7F16;&#x7801;&#x5668;&#x4E2D;&#x7684;&#x5D4C;&#x5165;&#x6E90;&#x5E8F;&#x5217;&#xFF09;&#x8F6C;&#x6362;&#x4E3A;PackedSequence&#xFF1A;&#x63D0;&#x4F9B;&#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#xFF0C;&#x5E76;&#x6839;&#x636E;&#x4EE5;&#x4E0B;&#x987A;&#x5E8F;&#x5BF9;&#x5C0F;&#x6279;&#x91CF;&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#x3002;&#x8FD9;&#x4E9B;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#x3002;&#x8FD9;&#x5728;&#x56FE;8-11&#x4E2D;&#x4EE5;&#x53EF;&#x89C6;&#x65B9;&#x5F0F;&#x663E;&#x793A;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x662F;&#x4E00;&#x4E2A;&#x590D;&#x6742;&#x7684;&#x4E3B;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x4F8B;8-6&#x53CA;&#x5176;&#x8F93;&#x51FA;&#x4E2D;&#x518D;&#x6B21;&#x6F14;&#x793A;&#x5B83;.</p>
<p>Example 8-6. A simple demonstration of packed_padded_sequences and pad_packed_sequences</p>
<pre><code class="lang-py">Input[<span class="hljs-number">0</span>]
abcd_padded = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], dtype=torch.float32)
efg_padded = torch.tensor([<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>], dtype=torch.float32)
h_padded = torch.tensor([<span class="hljs-number">8</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], dtype=torch.float32)

padded_tensor = torch.stack([abcd_padded, efg_padded, h_padded])

describe(padded_tensor)
Output[<span class="hljs-number">0</span>]
Type: torch.FloatTensor
Shape/size: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])
Values:
tensor([[ <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">4.</span>],
        [ <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">0.</span>],
        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>]])
Input[<span class="hljs-number">1</span>]
lengths = [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>]
packed_tensor = pack_padded_sequence(padded_tensor, lengths,   
                                     batch_first=<span class="hljs-keyword">True</span>)
packed_tensor
Output[<span class="hljs-number">1</span>]
PackedSequence(data=tensor([ <span class="hljs-number">1.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">8.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">4.</span>]),
               batch_sizes=tensor([ <span class="hljs-number">3</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">1</span>]))
Input[<span class="hljs-number">2</span>]
unpacked_tensor, unpacked_lengths = \
    pad_packed_sequence(packed_tensor, batch_first=<span class="hljs-keyword">True</span>)

describe(unpacked_tensor)
describe(unpacked_lengths)
Output[<span class="hljs-number">2</span>]
Type: torch.FloatTensor
Shape/size: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])
Values:
tensor([[ <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">4.</span>],
        [ <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">0.</span>],
        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>]])
Type: torch.LongTensor
Shape/size: torch.Size([<span class="hljs-number">3</span>])
Values:
tensor([ <span class="hljs-number">4</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">1</span>])
</code></pre>
<p>&#x6211;&#x4EEC;&#x5728;&#x751F;&#x6210;&#x6BCF;&#x4E2A;minibatch&#x65F6;&#x5904;&#x7406;&#x6392;&#x5E8F;&#xFF0C;&#x5982;&#x4E0A;&#x4E00;&#x8282;&#x6240;&#x8FF0;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x5982;&#x4F8B;8-7&#x6240;&#x793A;&#xFF0C;&#x901A;&#x8FC7;&#x4F20;&#x9012;&#x5D4C;&#x5165;&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#x548C;&#x8868;&#x793A;&#x7B2C;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x662F;&#x6279;&#x91CF;&#x7EF4;&#x5EA6;&#x7684;&#x5E03;&#x5C14;&#x6807;&#x5FD7;&#x6765;&#x6FC0;&#x53D1;PyTorch&#x7684;pack_padded_sequence&#x51FD;&#x6570;&#x3002;&#x6B64;&#x51FD;&#x6570;&#x7684;&#x8F93;&#x51FA;&#x662F;PackedSequence&#x3002;&#x5C06;&#x5F97;&#x5230;&#x7684;PackedSequence&#x8F93;&#x5165;&#x5230;bi-GRU&#x4E2D;&#x4EE5;&#x4E3A;&#x4E0B;&#x6E38;&#x89E3;&#x7801;&#x5668;&#x521B;&#x5EFA;&#x72B6;&#x6001;&#x5411;&#x91CF;&#x3002;&#x4F7F;&#x7528;&#x53E6;&#x4E00;&#x4E2A;&#x5E03;&#x5C14;&#x6807;&#x5FD7;&#x5C06;bi-GRU&#x7684;&#x8F93;&#x51FA;&#x89E3;&#x538B;&#x7F29;&#x4E3A;&#x5B8C;&#x6574;&#x5F20;&#x91CF;&#xFF0C;&#x6307;&#x793A;&#x6279;&#x5904;&#x7406;&#x5728;&#x7B2C;&#x4E00;&#x7EF4;&#x4E0A;&#x3002;&#x89E3;&#x5305;&#x64CD;&#x4F5C;&#xFF0C;&#x5982;&#x56FE;8-11&#x6240;&#x793A;&#xFF0C;&#x5C06;&#x6BCF;&#x4E2A;&#x5C4F;&#x853D;&#x4F4D;&#x7F6E;15&#x8BBE;&#x7F6E;&#x4E3A;&#x96F6;&#x503C;&#x5411;&#x91CF;&#xFF0C;&#x4FDD;&#x7559;&#x4E0B;&#x6E38;&#x8BA1;&#x7B97;&#x7684;&#x5B8C;&#x6574;&#x6027;&#x3002;</p>
<p>Example 8-7. The NMT Decoder constructs a target sentence from the encoded source sentence</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTDecoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        Args:
            num_embeddings (int): number of embeddings is also the number of
                unique words in target vocabulary
            embedding_size (int): the embedding vector size
            rnn_hidden_size (int): size of the hidden rnn state
            bos_index(int): begin-of-sequence index
        &quot;&quot;&quot;</span>
        super(NMTDecoder, self).__init__()
        self._rnn_hidden_size = rnn_hidden_size
        self.target_embedding = nn.Embedding(num_embeddings=num_embeddings,
                                             embedding_dim=embedding_size,
                                             padding_idx=<span class="hljs-number">0</span>)
        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size,
                                   rnn_hidden_size)
        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)
        self.classifier = nn.Linear(rnn_hidden_size * <span class="hljs-number">2</span>, num_embeddings)
        self.bos_index = bos_index

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_init_indices</span><span class="hljs-params">(self, batch_size)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot; return the BEGIN-OF-SEQUENCE index vector &quot;&quot;&quot;</span>
        <span class="hljs-keyword">return</span> torch.ones(batch_size, dtype=torch.int64) * self.bos_index

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_init_context_vectors</span><span class="hljs-params">(self, batch_size)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot; return a zeros vector for initializing the context &quot;&quot;&quot;</span>
        <span class="hljs-keyword">return</span> torch.zeros(batch_size, self._rnn_hidden_size)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, encoder_state, initial_hidden_state, target_sequence)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;The forward pass of the model

        Args:
            encoder_state (torch.Tensor): the output of the NMTEncoder
            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder
            target_sequence (torch.Tensor): the target text data tensor
            sample_probability (float): the schedule sampling parameter
                probability of using model&apos;s predictions at each decoder step
        Returns:
            output_vectors (torch.Tensor): prediction vectors at each output step
        &quot;&quot;&quot;</span>
        <span class="hljs-comment"># We are making an assumption there: The batch is on first</span>
        <span class="hljs-comment"># The input is (Batch, Seq)</span>
        <span class="hljs-comment"># We want to iterate over sequence so we permute it to (S, B)</span>
        target_sequence = target_sequence.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)

        <span class="hljs-comment"># use the provided encoder hidden state as the initial hidden state</span>
        h_t = self.hidden_map(initial_hidden_state)

        batch_size = encoder_state.size(<span class="hljs-number">0</span>)
        <span class="hljs-comment"># initialize context vectors to zeros</span>
        context_vectors = self._init_context_vectors(batch_size)
        <span class="hljs-comment"># initialize first y_t word as BOS</span>
        y_t_index = self._init_indices(batch_size)

        h_t = h_t.to(encoder_state.device)
        y_t_index = y_t_index.to(encoder_state.device)
        context_vectors = context_vectors.to(encoder_state.device)

        output_vectors = []
        <span class="hljs-comment"># All cached tensors are moved from the GPU and stored for analysis</span>
        self._cached_p_attn = []
        self._cached_ht = []
        self._cached_decoder_state = encoder_state.cpu().detach().numpy()

        output_sequence_size = target_sequence.size(<span class="hljs-number">0</span>)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(output_sequence_size):

            <span class="hljs-comment"># Step 1: Embed word and concat with previous context</span>
            y_input_vector = self.target_embedding(target_sequence[i])
            rnn_input = torch.cat([y_input_vector, context_vectors], dim=<span class="hljs-number">1</span>)

            <span class="hljs-comment"># Step 2: Make a GRU step, getting a new hidden vector</span>
            h_t = self.gru_cell(rnn_input, h_t)
            self._cached_ht.append(h_t.cpu().data.numpy())

            <span class="hljs-comment"># Step 3: Use the current hidden to attend to the encoder state</span>
            context_vectors, p_attn, _ = \
                verbose_attention(encoder_state_vectors=encoder_state,
                                  query_vector=h_t)

            <span class="hljs-comment"># auxiliary: cache the attention probabilities for visualization</span>
            self._cached_p_attn.append(p_attn.cpu().detach().numpy())

            <span class="hljs-comment"># Step 4: Use the current hidden and context vectors</span>
            <span class="hljs-comment">#         to make a prediction to the next word</span>
            prediction_vector = torch.cat((context_vectors, h_t), dim=<span class="hljs-number">1</span>)
            score_for_y_t_index = self.classifier(prediction_vector)

            <span class="hljs-comment"># auxiliary: collect the prediction scores</span>
            output_vectors.append(score_for_y_t_index)
</code></pre>
<p>&#x5728;&#x7F16;&#x7801;&#x5668;&#x5229;&#x7528;&#x5176;bi-GRU&#x548C;&#x6253;&#x5305; - &#x89E3;&#x5305;&#x534F;&#x8C03;&#x521B;&#x5EFA;&#x72B6;&#x6001;&#x5411;&#x91CF;&#x4E4B;&#x540E;&#xFF0C;&#x89E3;&#x7801;&#x5668;&#x5728;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x4E0A;&#x8FED;&#x4EE3;&#x4EE5;&#x751F;&#x6210;&#x8F93;&#x51FA;&#x5E8F;&#x5217;&#x3002;&#x5728;&#x529F;&#x80FD;&#x4E0A;&#xFF0C;&#x8FD9;&#x4E2A;&#x5FAA;&#x73AF;&#x5E94;&#x8BE5;&#x770B;&#x8D77;&#x6765;&#x4E0E;&#x7B2C;7&#x7AE0;&#x4E2D;&#x7684;&#x751F;&#x6210;&#x5FAA;&#x73AF;&#x975E;&#x5E38;&#x76F8;&#x4F3C;&#xFF0C;&#x4F46;&#x662F;&#x6709;&#x4E00;&#x4E9B;&#x5DEE;&#x5F02;&#x660E;&#x663E;&#x662F;Luong&#x7B49;&#x4EBA;&#x7684;&#x6CE8;&#x610F;&#x65B9;&#x5F0F;&#x7684;&#x65B9;&#x6CD5;&#x9009;&#x62E9;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x63D0;&#x4F9B;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x89C2;&#x5BDF;&#x3002;&#x901A;&#x8FC7;&#x4F7F;&#x7528;GRUCell&#x8BA1;&#x7B97;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x3002;&#x901A;&#x8FC7;&#x5C06;&#x7EBF;&#x6027;&#x5C42;&#x5E94;&#x7528;&#x4E8E;&#x7F16;&#x7801;&#x5668;bi-GRU&#x7684;&#x7EA7;&#x8054;&#x6700;&#x7EC8;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x6765;&#x8BA1;&#x7B97;&#x521D;&#x59CB;&#x9690;&#x85CF;&#x72B6;&#x6001;.&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x5904;&#x5BF9;&#x89E3;&#x7801;&#x5668;GRU&#x7684;&#x8F93;&#x5165;&#x662F;&#x5D4C;&#x5165;&#x5F0F;&#x8F93;&#x5165;&#x4EE4;&#x724C;&#x548C;&#x6700;&#x540E;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x7684;&#x7EA7;&#x8054;&#x5411;&#x91CF;&#x3002;&#x5411;&#x91CF;&#x3002;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x65E8;&#x5728;&#x6355;&#x83B7;&#x5BF9;&#x8BE5;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x6709;&#x7528;&#x7684;&#x4FE1;&#x606F;&#xFF0C;&#x5E76;&#x7528;&#x4E8E;&#x8C03;&#x8282;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x3002;&#x5BF9;&#x4E8E;&#x7B2C;&#x4E00;&#x4E2A;&#x6B65;&#x9AA4;&#xFF0C;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x5168;&#x90E8;&#x4E3A;0&#xFF08;&#x96F6;&#xFF09;&#x4EE5;&#x8868;&#x793A;&#x65E0;&#x4E0A;&#x4E0B;&#x6587;&#x5E76;&#x4E14;&#x5728;&#x6570;&#x5B66;&#x4E0A;&#x4EC5;&#x5141;&#x8BB8;&#x8F93;&#x5165;&#x5BF9;GRU&#x8BA1;&#x7B97;&#x505A;&#x51FA;&#x8D21;&#x732E;&#x3002;</p>
<p>&#x4F7F;&#x7528;&#x65B0;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4F5C;&#x4E3A;&#x67E5;&#x8BE2;&#x5411;&#x91CF;&#xFF0C;&#x4F7F;&#x7528;&#x5F53;&#x524D;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x7684;&#x5173;&#x6CE8;&#x673A;&#x5236;&#x521B;&#x5EFA;&#x4E00;&#x7EC4;&#x65B0;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x3002;&#x8FD9;&#x4E9B;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x4E0E;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x8FDE;&#x63A5;&#x4EE5;&#x521B;&#x5EFA;&#x8868;&#x793A;&#x8BE5;&#x65F6;&#x95F4;&#x6B65;&#x957F;&#x5904;&#x7684;&#x89E3;&#x7801;&#x4FE1;&#x606F;&#x7684;&#x5411;&#x91CF;&#x3002;&#x8BE5;&#x89E3;&#x7801;&#x4FE1;&#x606F;&#x72B6;&#x6001;&#x5411;&#x91CF;&#x7528;&#x5728;&#x5206;&#x7C7B;&#x5668;&#xFF08;&#x5728;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x7B80;&#x5355;&#x7684;&#x7EBF;&#x6027;&#x5C42;&#xFF09;&#x4E2D;&#x4EE5;&#x521B;&#x5EFA;&#x9884;&#x6D4B;&#x5411;&#x91CF;score_for_y_t_index&#x3002;&#x8FD9;&#x4E9B;&#x9884;&#x6D4B;&#x77E2;&#x91CF;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;softmax&#x51FD;&#x6570;&#x8F6C;&#x6362;&#x4E3A;&#x8F93;&#x51FA;&#x8BCD;&#x6C47;&#x8868;&#x4E0A;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#xFF0C;&#x6216;&#x8005;&#x5B83;&#x4EEC;&#x53EF;&#x4EE5;&#x4E0E;&#x4EA4;&#x53C9;&#x71B5;&#x635F;&#x5931;&#x4E00;&#x8D77;&#x4F7F;&#x7528;&#x4EE5;&#x4F18;&#x5316;&#x5730;&#x9762;&#x5B9E;&#x51B5;&#x76EE;&#x6807;&#x3002;&#x5728;&#x6211;&#x4EEC;&#x8F6C;&#x5411;&#x5982;&#x4F55;&#x5728;&#x8BAD;&#x7EC3;&#x4F8B;&#x7A0B;&#x4E2D;&#x4F7F;&#x7528;&#x9884;&#x6D4B;&#x5411;&#x91CF;&#x4E4B;&#x524D;&#xFF0C;&#x6211;&#x4EEC;&#x9996;&#x5148;&#x68C0;&#x67E5;&#x6CE8;&#x610F;&#x529B;&#x8BA1;&#x7B97;&#x672C;&#x8EAB;&#x3002;</p>
<p>A CLOSER LOOK AT ATTENTION &#x4E86;&#x89E3;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x5728;&#x6B64;&#x793A;&#x4F8B;&#x4E2D;&#x7684;&#x5DE5;&#x4F5C;&#x65B9;&#x5F0F;&#x975E;&#x5E38;&#x91CD;&#x8981;&#x3002;&#x56DE;&#x60F3;&#x4E00;&#x4E0B;&#x524D;&#x9762;&#x7684;&#x90E8;&#x5206;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x67E5;&#x8BE2;&#xFF0C;&#x952E;&#x548C;&#x503C;&#x6765;&#x63CF;&#x8FF0;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x3002;&#x5206;&#x6570;&#x51FD;&#x6570;&#x5C06;&#x67E5;&#x8BE2;&#x5411;&#x91CF;&#x548C;&#x5173;&#x952E;&#x5411;&#x91CF;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x4EE5;&#x8BA1;&#x7B97;&#x5728;&#x503C;&#x5411;&#x91CF;&#x4E2D;&#x9009;&#x62E9;&#x7684;&#x4E00;&#x7EC4;&#x6743;&#x91CD;&#x3002;&#x5728;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x70B9;&#x79EF;&#x8BC4;&#x5206;&#x51FD;&#x6570;&#xFF0C;&#x4F46;&#x5B83;&#x4E0D;&#x662F;&#x552F;&#x4E00;&#x7684;.&#x5728;&#x8FD9;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x89E3;&#x7801;&#x5668;&#x7684;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x88AB;&#x7528;&#x4F5C;&#x67E5;&#x8BE2;&#x5411;&#x91CF;&#xFF0C;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x5411;&#x91CF;&#x96C6;&#x662F;&#x5173;&#x952E;&#x548C;&#x503C;&#x5411;&#x91CF;&#x3002;</p>
<p>&#x89E3;&#x7801;&#x5668;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4E0E;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x4E2D;&#x7684;&#x77E2;&#x91CF;&#x7684;&#x70B9;&#x79EF;&#x4E3A;&#x7F16;&#x7801;&#x5E8F;&#x5217;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x9879;&#x521B;&#x5EFA;&#x6807;&#x91CF;&#x3002;&#x5728;&#x4F7F;&#x7528;softmax&#x51FD;&#x6570;&#x65F6;&#xFF0C;&#x8FD9;&#x4E9B;&#x6807;&#x91CF;&#x53D8;&#x4E3A;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x4E2D;&#x7684;&#x77E2;&#x91CF;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#x3002;&#x8FD9;&#x4E9B;&#x6982;&#x7387;&#x7528;&#x4E8E;&#x5728;&#x5C06;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x5411;&#x91CF;&#x52A0;&#x5728;&#x4E00;&#x8D77;&#x4E4B;&#x524D;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x52A0;&#x6743;&#xFF0C;&#x4EE5;&#x4EA7;&#x751F;&#x6BCF;&#x4E2A;&#x6279;&#x6B21;&#x9879;&#x76EE;&#x7684;&#x5355;&#x4E2A;&#x5411;&#x91CF;&#x3002;&#x603B;&#x800C;&#x8A00;&#x4E4B;&#xFF0C;&#x5141;&#x8BB8;&#x89E3;&#x7801;&#x5668;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x4F18;&#x5148;&#x52A0;&#x6743;&#x7F16;&#x7801;&#x5668;&#x72B6;&#x6001;&#x3002;&#x8FD9;&#x5C31;&#x50CF;&#x4E00;&#x4E2A;&#x805A;&#x5149;&#x706F;&#xFF0C;&#x4F7F;&#x6A21;&#x578B;&#x80FD;&#x591F;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x7A81;&#x51FA;&#x663E;&#x793A;&#x751F;&#x6210;&#x8F93;&#x51FA;&#x5E8F;&#x5217;&#x6240;&#x9700;&#x7684;&#x4FE1;&#x606F;&#x3002;&#x6211;&#x4EEC;&#x5728;&#x4F8B;8-8&#x4E2D;&#x6F14;&#x793A;&#x4E86;&#x8FD9;&#x79CD;&#x7248;&#x672C;&#x7684;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x3002;&#x7B2C;&#x4E00;&#x4E2A;&#x5C1D;&#x8BD5;&#x8BE6;&#x7EC6;&#x8BF4;&#x660E;&#x64CD;&#x4F5C;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x5B83;&#x4F7F;&#x7528;&#x89C6;&#x56FE;&#x64CD;&#x4F5C;&#x63D2;&#x5165;&#x5927;&#x5C0F;&#x4E3A;1&#x7684;&#x7EF4;&#x5EA6;&#xFF0C;&#x4EE5;&#x4FBF;&#x53EF;&#x4EE5;&#x9488;&#x5BF9;&#x53E6;&#x4E00;&#x4E2A;&#x5F20;&#x91CF;&#x5E7F;&#x64AD;&#x5F20;&#x91CF;&#x3002;&#x5728;terse_attention&#x7248;&#x672C;&#x4E2D;&#xFF0C;&#x89C6;&#x56FE;&#x64CD;&#x4F5C;&#x88AB;&#x66F4;&#x5E38;&#x7528;&#x7684;&#x7EC3;&#x4E60;&#x66FF;&#x6362;&#xFF0C;&#x53D6;&#x6D88;&#x538B;&#x7F29;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x4E0D;&#x662F;&#x5C06;&#x5143;&#x7D20;&#x548C;&#x6C42;&#x548C;&#x76F8;&#x4E58;&#xFF0C;&#x800C;&#x662F;&#x4F7F;&#x7528;&#x66F4;&#x6709;&#x6548;&#x7684;matmul&#x8FD0;&#x7B97;&#x3002;</p>
<p>Example 8-8. Attention that does element-wise multiplication and summing more explicitly</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">verbose_attention</span><span class="hljs-params">(encoder_state_vectors, query_vector)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    encoder_state_vectors: 3dim tensor from bi-GRU in encoder
    query_vector: hidden state in decoder GRU
    &quot;&quot;&quot;</span>
    batch_size, num_vectors, vector_size = encoder_state_vectors.size()
    vector_scores = \
        torch.sum(encoder_state_vectors * query_vector.view(batch_size, <span class="hljs-number">1</span>,
                                                            vector_size),
                  dim=<span class="hljs-number">2</span>)
    vector_probabilities = F.softmax(vector_scores, dim=<span class="hljs-number">1</span>)
    weighted_vectors = \
        encoder_state_vectors * vector_probabilities.view(batch_size,
                                                          num_vectors, <span class="hljs-number">1</span>)
    context_vectors = torch.sum(weighted_vectors, dim=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> context_vectors, vector_probabilities

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">terse_attention</span><span class="hljs-params">(encoder_state_vectors, query_vector)</span>:</span>
    <span class="hljs-string">&quot;&quot;&quot;
    encoder_state_vectors: 3dim tensor from bi-GRU in encoder
    query_vector: hidden state
    &quot;&quot;&quot;</span>
    vector_scores = torch.matmul(encoder_state_vectors,
                                 query_vector.unsqueeze(dim=<span class="hljs-number">2</span>)).squeeze()
    vector_probabilities = F.softmax(vector_scores, dim=<span class="hljs-number">-1</span>)
    context_vectors = torch.matmul(encoder_state_vectors.transpose(<span class="hljs-number">-2</span>, <span class="hljs-number">-1</span>),
                                   vector_probabilities.unsqueeze(dim=<span class="hljs-number">2</span>)).squeeze()
    <span class="hljs-keyword">return</span> context_vectors, vector_probabilities
</code></pre>
<p>LEARNING TO SEARCH AND SCHEDULED SAMPLING</p>
<p>&#x5F53;&#x524D;&#x7F16;&#x5199;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x6A21;&#x578B;&#x5047;&#x5B9A;&#x63D0;&#x4F9B;&#x4E86;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#xFF0C;&#x5E76;&#x5C06;&#x5728;&#x89E3;&#x7801;&#x5668;&#x7684;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x9AA4;&#x7528;&#x4F5C;&#x8F93;&#x5165;&#x3002;&#x5728;&#x6D4B;&#x8BD5;&#x65F6;&#xFF0C;&#x8FDD;&#x53CD;&#x4E86;&#x8FD9;&#x4E2A;&#x5047;&#x8BBE;&#xFF0C;&#x56E0;&#x4E3A;&#x6A21;&#x578B;&#x4E0D;&#x80FD;&#x4F5C;&#x5F0A;&#x5E76;&#x4E14;&#x77E5;&#x9053;&#x5B83;&#x8BD5;&#x56FE;&#x751F;&#x6210;&#x7684;&#x5E8F;&#x5217;&#x3002;&#x4E3A;&#x4E86;&#x9002;&#x5E94;&#x8FD9;&#x4E00;&#x4E8B;&#x5B9E;&#xFF0C;&#x4E00;&#x79CD;&#x6280;&#x672F;&#x662F;&#x5141;&#x8BB8;&#x6A21;&#x578B;&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#x4F7F;&#x7528;&#x81EA;&#x5DF1;&#x7684;&#x9884;&#x6D4B;&#x3002;&#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x5728;&#x6587;&#x732E;&#x4E2D;&#x63A2;&#x7D22;&#x4E3A;&#x201C;&#x5B66;&#x4E60;&#x641C;&#x7D22;&#x201D;&#x548C;&#x201C;&#x9884;&#x5B9A;&#x62BD;&#x6837;&#x201D;&#x7684;&#x6280;&#x672F;.&#x7406;&#x89E3;&#x8FD9;&#x79CD;&#x6280;&#x672F;&#x7684;&#x4E00;&#x79CD;&#x76F4;&#x89C2;&#x65B9;&#x6CD5;&#x662F;&#x5C06;&#x9884;&#x6D4B;&#x95EE;&#x9898;&#x89C6;&#x4E3A;&#x641C;&#x7D22;&#x95EE;&#x9898;&#x3002;&#x5728;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#xFF0C;&#x6A21;&#x578B;&#x6709;&#x8BB8;&#x591A;&#x8DEF;&#x5F84;&#x53EF;&#x4F9B;&#x9009;&#x62E9;&#xFF08;&#x9009;&#x62E9;&#x7684;&#x6570;&#x91CF;&#x662F;&#x76EE;&#x6807;&#x8BCD;&#x6C47;&#x7684;&#x5927;&#x5C0F;&#xFF09;&#xFF0C;&#x6570;&#x636E;&#x662F;&#x6B63;&#x786E;&#x8DEF;&#x5F84;&#x7684;&#x89C2;&#x5BDF;&#x3002;&#x5728;&#x6D4B;&#x8BD5;&#x65F6;&#xFF0C;&#x6A21;&#x578B;&#x6700;&#x7EC8;&#x88AB;&#x5141;&#x8BB8;&#x201C;&#x79BB;&#x5F00;&#x8DEF;&#x5F84;&#x201D;&#xFF0C;&#x56E0;&#x4E3A;&#x6CA1;&#x6709;&#x63D0;&#x4F9B;&#x6B63;&#x786E;&#x7684;&#x8DEF;&#x5F84;&#xFF0C;&#x5B83;&#x5E94;&#x8BE5;&#x4ECE;&#x4E2D;&#x8BA1;&#x7B97;&#x6982;&#x7387;&#x5206;&#x5E03;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x8BA9;&#x6A21;&#x578B;&#x91C7;&#x6837;&#x81EA;&#x5DF1;&#x7684;&#x8DEF;&#x5F84;&#x7684;&#x6280;&#x672F;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#xFF0C;&#x5728;&#x8BE5;&#x65B9;&#x6CD5;&#x4E2D;&#xFF0C;&#x5F53;&#x6A21;&#x578B;&#x504F;&#x79BB;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#x7684;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x4F18;&#x5316;&#x6A21;&#x578B;&#x4EE5;&#x83B7;&#x5F97;&#x66F4;&#x597D;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#x3002;</p>
<p>&#x4EE3;&#x7801;&#x6709;&#x4E09;&#x4E2A;&#x4E3B;&#x8981;&#x4FEE;&#x6539;&#xFF0C;&#x4EE5;&#x4F7F;&#x6A21;&#x578B;&#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;&#x91C7;&#x6837;&#x81EA;&#x5DF1;&#x7684;&#x9884;&#x6D4B;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x521D;&#x59CB;&#x7D22;&#x5F15;&#x66F4;&#x660E;&#x786E;&#x5730;&#x4F5C;&#x4E3A;BEGIN-OF-SEQUENCE&#x6807;&#x8BB0;&#x7D22;&#x5F15;&#x3002;&#x5176;&#x6B21;&#xFF0C;&#x4E3A;&#x751F;&#x6210;&#x5FAA;&#x73AF;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x6B65;&#x9AA4;&#x7ED8;&#x5236;&#x968F;&#x673A;&#x6837;&#x672C;&#xFF0C;&#x5982;&#x679C;&#x968F;&#x673A;&#x6837;&#x672C;&#x5C0F;&#x4E8E;&#x6837;&#x672C;&#x6982;&#x7387;&#xFF0C;&#x5219;&#x5728;&#x8BE5;&#x8FED;&#x4EE3;&#x671F;&#x95F4;&#x4F7F;&#x7528;&#x6A21;&#x578B;&#x7684;&#x9884;&#x6D4B;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x7B2C;&#x4E09;&#x4E2A;&#x5B9E;&#x9645;&#x91C7;&#x6837;&#x672C;&#x8EAB;&#x5728;&#x6761;&#x4EF6;if&#x4E0B;&#x4F7F;&#x7528;use_sample&#x3002;&#x5728;&#x793A;&#x4F8B;8-9&#x4E2D;&#xFF0C;&#x6CE8;&#x91CA;&#x884C;&#x663E;&#x793A;&#x4E86;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x6700;&#x5927;&#x9884;&#x6D4B;&#xFF0C;&#x800C;&#x672A;&#x6CE8;&#x91CA;&#x884C;&#x663E;&#x793A;&#x4E86;&#x5982;&#x4F55;&#x4EE5;&#x4E0E;&#x5176;&#x6982;&#x7387;&#x6210;&#x6BD4;&#x4F8B;&#x7684;&#x901F;&#x7387;&#x5B9E;&#x9645;&#x91C7;&#x6837;&#x7D22;&#x5F15;&#x3002;</p>
<p>Example 8-9. The decoder with a sampling procedures (in bold) built into the forward pass</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NMTDecoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_embeddings, embedding_size, rnn_size, bos_index)</span>:</span>
        super(NMTDecoder, self).__init__()
        <span class="hljs-comment"># ... other init code here ...</span>

        <span class="hljs-comment"># arbitrarily set; any small constant will be fine</span>
        self._sampling_temperature = <span class="hljs-number">3</span>

   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, encoder_state, initial_hidden_state, target_sequence,
               sample_probability=<span class="hljs-number">0.0</span>)</span>:</span>
        <span class="hljs-keyword">if</span> target_sequence <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
            sample_probability = <span class="hljs-number">1.0</span>
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># We are making an assumption there: The batch is on first</span>
            <span class="hljs-comment"># The input is (Batch, Seq)</span>
            <span class="hljs-comment"># We want to iterate over sequence so we permute it to (S, B)</span>
            target_sequence = target_sequence.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)
            output_sequence_size = target_sequence.size(<span class="hljs-number">0</span>)

        <span class="hljs-comment"># ... nothing changes from the other implementation</span>

        output_sequence_size = target_sequence.size(<span class="hljs-number">0</span>)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(output_sequence_size):
            <span class="hljs-comment"># new: a helper boolean and the teacher y_t_index</span>
            use_sample = np.random.random() &lt; sample_probability
            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> use_sample:
                y_t_index = target_sequence[i]

            <span class="hljs-comment"># Step 1: Embed word and concat with previous context</span>
            <span class="hljs-comment"># ... code omitted for space</span>
            <span class="hljs-comment"># Step 2: Make a GRU step, getting a new hidden vector</span>
            <span class="hljs-comment"># ... code omitted for space</span>
            <span class="hljs-comment"># Step 3: Use the current hidden to attend to the encoder state</span>
            <span class="hljs-comment"># ... code omitted for space</span>
            <span class="hljs-comment"># Step 4: Use the current hidden and context vectors</span>
            <span class="hljs-comment">#         to make a prediction to the next word</span>
            prediction_vector = torch.cat((context_vectors, h_t), dim=<span class="hljs-number">1</span>)
            score_for_y_t_index = self.classifier(prediction_vector)
            <span class="hljs-comment"># new: sampling if boolean is true.</span>
            <span class="hljs-keyword">if</span> use_sample:
                <span class="hljs-comment"># sampling temperature forces a peakier distribution</span>
                p_y_t_index = F.softmax(score_for_y_t_index *
                                        self._sampling_temperature, dim=<span class="hljs-number">1</span>)
                <span class="hljs-comment"># method 1: choose most likely word</span>
                <span class="hljs-comment"># _, y_t_index = torch.max(p_y_t_index, 1)</span>
                <span class="hljs-comment"># method 2: sample from the distribution</span>
                y_t_index = torch.multinomial(p_y_t_index, <span class="hljs-number">1</span>).squeeze()

            <span class="hljs-comment"># auxiliary: collect the prediction scores</span>
            output_vectors.append(score_for_y_t_index)

        output_vectors = torch.stack(output_vectors).permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)

        <span class="hljs-keyword">return</span> output_vectors
</code></pre>
<h3 id="training-routine-and-results">Training Routine and Results</h3>
<p>&#x6B64;&#x793A;&#x4F8B;&#x7684;&#x8BAD;&#x7EC3;&#x4F8B;&#x7A0B;&#x51E0;&#x4E4E;&#x4E0E;&#x524D;&#x9762;&#x7AE0;&#x8282;&#x4E2D;&#x4ECB;&#x7ECD;&#x7684;&#x8BAD;&#x7EC3;&#x4F8B;&#x7A0B;&#x76F8;&#x540C;&#x3002;&#x5BF9;&#x4E8E;&#x56FA;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x5386;&#x5143;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x79F0;&#x4E3A;minibatches&#x7684;&#x5757;&#x4E2D;&#x8FED;&#x4EE3;&#x6570;&#x636E;&#x96C6;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x8FD9;&#x91CC;&#x7684;&#x6BCF;&#x4E2A;&#x5C0F;&#x6279;&#x91CF;&#x7531;&#x56DB;&#x4E2A;&#x5F20;&#x91CF;&#x7EC4;&#x6210;&#xFF1A;&#x6E90;&#x5E8F;&#x5217;&#x7684;&#x6574;&#x6570;&#x77E9;&#x9635;&#xFF0C;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x7684;&#x4E24;&#x4E2A;&#x6574;&#x6570;&#x77E9;&#x9635;&#xFF0C;&#x4EE5;&#x53CA;&#x6E90;&#x5E8F;&#x5217;&#x957F;&#x5EA6;&#x7684;&#x6574;&#x6570;&#x5411;&#x91CF;&#x3002;&#x4E24;&#x4E2A;&#x9776;&#x5E8F;&#x5217;&#x77E9;&#x9635;&#x662F;&#x9776;&#x5E8F;&#x5217;&#x504F;&#x79FB;1&#x5E76;&#x7528;BEGIN-OF-SEQUENCE&#x4EE4;&#x724C;&#x586B;&#x5145;&#x4EE5;&#x5145;&#x5F53;&#x9776;&#x5E8F;&#x5217;&#x89C2;&#x5BDF;&#xFF0C;&#x6216;END-OF-SEQUENCE&#x4EE4;&#x724C;&#x5145;&#x5F53;&#x9776;&#x5E8F;&#x5217;&#x9884;&#x6D4B;&#x6807;&#x8BB0;&#x3002;&#x8BE5;&#x6A21;&#x578B;&#x5C06;&#x6E90;&#x5E8F;&#x5217;&#x548C;&#x200B;&#x200B;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x89C2;&#x5BDF;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x4EE5;&#x4EA7;&#x751F;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x9884;&#x6D4B;&#x3002;&#x5728;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4E2D;&#x4F7F;&#x7528;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x9884;&#x6D4B;&#x6807;&#x7B7E;&#x6765;&#x8BA1;&#x7B97;&#x4EA4;&#x53C9;&#x71B5;&#x635F;&#x5931;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x5176;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x5230;&#x6BCF;&#x4E2A;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x4EE5;&#x4F7F;&#x5176;&#x77E5;&#x9053;&#x5176;&#x68AF;&#x5EA6;&#x3002;&#x7136;&#x540E;&#x8C03;&#x7528;&#x4F18;&#x5316;&#x5668;&#x5E76;&#x5C06;&#x6BCF;&#x4E2A;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x66F4;&#x65B0;&#x4E00;&#x4E9B;&#x4E0E;&#x68AF;&#x5EA6;&#x6210;&#x6BD4;&#x4F8B;&#x7684;&#x91CF;&#x3002;</p>
<p>&#x9664;&#x4E86;&#x6570;&#x636E;&#x96C6;&#x7684;&#x8BAD;&#x7EC3;&#x90E8;&#x5206;&#x4E0A;&#x7684;&#x5FAA;&#x73AF;&#x4E4B;&#x5916;&#xFF0C;&#x9A8C;&#x8BC1;&#x90E8;&#x5206;&#x4E0A;&#x8FD8;&#x6709;&#x4E00;&#x4E2A;&#x5FAA;&#x73AF;&#x3002;&#x9A8C;&#x8BC1;&#x5206;&#x6570;&#x7528;&#x4F5C;&#x6A21;&#x578B;&#x6539;&#x8FDB;&#x7684;&#x504F;&#x5DEE;&#x8F83;&#x5C0F;&#x7684;&#x5EA6;&#x91CF;&#x3002;&#x8BE5;&#x8FC7;&#x7A0B;&#x4E0E;&#x8BAD;&#x7EC3;&#x4F8B;&#x7A0B;&#x76F8;&#x540C;&#xFF0C;&#x53EA;&#x662F;&#x6A21;&#x578B;&#x5904;&#x4E8E;eval&#x6A21;&#x5F0F;&#x5E76;&#x4E14;&#x6A21;&#x578B;&#x672A;&#x76F8;&#x5BF9;&#x4E8E;&#x9A8C;&#x8BC1;&#x6570;&#x636E;&#x66F4;&#x65B0;&#x3002;</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x6A21;&#x578B;&#x4E4B;&#x540E;&#xFF0C;&#x6D4B;&#x91CF;&#x6027;&#x80FD;&#x6210;&#x4E3A;&#x4E00;&#x4E2A;&#x91CD;&#x8981;&#x800C;&#x91CD;&#x8981;&#x7684;&#x95EE;&#x9898;&#x3002;&#x5728;&#x201C;&#x8BC4;&#x4F30;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x6A21;&#x578B;&#x201D;&#x4E2D;&#x63CF;&#x8FF0;&#x4E86;&#x51E0;&#x4E2A;&#x5E8F;&#x5217;&#x751F;&#x6210;&#x8BC4;&#x4F30;&#x5EA6;&#x91CF;&#xFF0C;&#x4F46;&#x662F;&#x8BF8;&#x5982;&#x6D4B;&#x91CF;&#x9884;&#x6D4B;&#x53E5;&#x5B50;&#x548C;&#x53C2;&#x8003;&#x8BED;&#x53E5;&#x4E4B;&#x95F4;&#x7684;n-gram&#x91CD;&#x53E0;&#x7684;BLEU&#x7684;&#x5EA6;&#x91CF;&#x5DF2;&#x7ECF;&#x6210;&#x4E3A;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x9886;&#x57DF;&#x7684;&#x6807;&#x51C6;&#x3002;&#x805A;&#x5408;&#x7ED3;&#x679C;&#x7684;&#x8BC4;&#x4F30;&#x4EE3;&#x7801;&#x5DF2;&#x88AB;&#x7701;&#x7565;&#xFF0C;&#x4F46;&#x60A8;&#x53EF;&#x4EE5;&#x5728;&#x672C;&#x4E66;&#x7684;&#x968F;&#x9644;&#x4EE3;&#x7801;&#x5E93;&#x4E2D;&#x627E;&#x5230;&#x5B83;.&#x5728;&#x4EE3;&#x7801;&#x4E2D;&#xFF0C;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x4E0E;&#x6E90;&#x53E5;&#x5B50;&#xFF0C;&#x53C2;&#x8003;&#x76EE;&#x6807;&#x8BED;&#x53E5;&#x548C;&#x6CE8;&#x610F;&#x6982;&#x7387;&#x77E9;&#x9635;&#x805A;&#x5408;&#x5728;&#x4E00;&#x8D77;&#x3002;&#x4F8B;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x4E3A;&#x6BCF;&#x5BF9;&#x6E90;&#x548C;&#x751F;&#x6210;&#x7684;&#x53E5;&#x5B50;&#x8BA1;&#x7B97;BLEU-4&#x3002;</p>
<p>&#x4E3A;&#x4E86;&#x5B9A;&#x6027;&#x8BC4;&#x4F30;&#x6A21;&#x578B;&#x7684;&#x5DE5;&#x4F5C;&#x60C5;&#x51B5;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x6CE8;&#x610F;&#x6982;&#x7387;&#x77E9;&#x9635;&#x53EF;&#x89C6;&#x5316;&#x4E3A;&#x6E90;&#x548C;&#x751F;&#x6210;&#x6587;&#x672C;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x9F50;&#x3002;&#x7136;&#x800C;&#xFF0C;&#x503C;&#x5F97;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x6700;&#x8FD1;&#x7684;&#x7814;&#x7A76;&#x8868;&#x660E;&#xFF0C;&#x57FA;&#x4E8E;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x5BF9;&#x9F50;&#x4E0E;&#x7ECF;&#x5178;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x4E2D;&#x7684;&#x5BF9;&#x9F50;&#x5E76;&#x4E0D;&#x5B8C;&#x5168;&#x76F8;&#x540C;&#x3002;&#x57FA;&#x4E8E;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x5BF9;&#x9F50;&#x5206;&#x6570;&#x53EF;&#x4EE5;&#x6307;&#x793A;&#x89E3;&#x7801;&#x5668;&#x7684;&#x6709;&#x7528;&#x4FE1;&#x606F;&#xFF0C;&#x4F8B;&#x5982;&#x5728;&#x751F;&#x6210;&#x8F93;&#x51FA;&#x52A8;&#x8BCD;&#x65F6;&#x53C2;&#x4E0E;&#x53E5;&#x5B50;&#x7684;&#x4E3B;&#x8BED;&#xFF08;Koehn&#x548C;Knowles&#xFF0C;2017&#xFF09;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x5355;&#x8BCD;&#x548C;&#x77ED;&#x8BED;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x9F50;&#x6307;&#x793A;&#x7FFB;&#x8BD1;&#x540C;&#x4E49;&#x8BCD;&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x6BD4;&#x8F83;&#x4E86;&#x6211;&#x4EEC;&#x6A21;&#x578B;&#x7684;&#x4E24;&#x4E2A;&#x7248;&#x672C;&#xFF0C;&#x5B83;&#x4EEC;&#x4E0E;&#x76EE;&#x6807;&#x53E5;&#x5B50;&#x7684;&#x4EA4;&#x4E92;&#x65B9;&#x5F0F;&#x4E0D;&#x540C;&#x3002;&#x7B2C;&#x4E00;&#x4E2A;&#x7248;&#x672C;&#x4F7F;&#x7528;&#x63D0;&#x4F9B;&#x7684;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x89E3;&#x7801;&#x5668;&#x4E2D;&#x6BCF;&#x4E2A;&#x65F6;&#x95F4;&#x6B65;&#x7684;&#x8F93;&#x5165;&#x3002;&#x7B2C;&#x4E8C;&#x4E2A;&#x7248;&#x672C;&#x4F7F;&#x7528;&#x9884;&#x5B9A;&#x91C7;&#x6837;&#xFF0C;&#x4EE5;&#x5141;&#x8BB8;&#x6A21;&#x578B;&#x5C06;&#x5176;&#x81EA;&#x5DF1;&#x7684;&#x9884;&#x6D4B;&#x89C6;&#x4E3A;&#x89E3;&#x7801;&#x5668;&#x4E2D;&#x7684;&#x8F93;&#x5165;&#x3002;&#x8FD9;&#x6709;&#x5229;&#x4E8E;&#x5F3A;&#x5236;&#x6A21;&#x578B;&#x4F18;&#x5316;&#x5176;&#x81EA;&#x8EAB;&#x7684;&#x9519;&#x8BEF;&#x3002;&#x8868;8-1&#x663E;&#x793A;&#x4E86;BLEU&#x5206;&#x6570;&#x3002;&#x91CD;&#x8981;&#x7684;&#x662F;&#x8981;&#x8BB0;&#x4F4F;&#xFF0C;&#x4E3A;&#x4E86;&#x4FBF;&#x4E8E;&#x8BAD;&#x7EC3;&#xFF0C;&#x6211;&#x4EEC;&#x9009;&#x62E9;&#x4E86;&#x6807;&#x51C6;NMT&#x4EFB;&#x52A1;&#x7684;&#x7B80;&#x5316;&#x7248;&#x672C;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;&#x4E3A;&#x4EC0;&#x4E48;&#x5206;&#x6570;&#x4F3C;&#x4E4E;&#x9AD8;&#x4E8E;&#x60A8;&#x5728;&#x7814;&#x7A76;&#x6587;&#x732E;&#x4E2D;&#x901A;&#x5E38;&#x4F1A;&#x53D1;&#x73B0;&#x7684;&#x5206;&#x6570;&#x3002;&#x867D;&#x7136;&#x7B2C;&#x4E8C;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x5373;&#x5177;&#x6709;&#x9884;&#x5B9A;&#x91C7;&#x6837;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x5177;&#x6709;&#x66F4;&#x9AD8;&#x7684;BLEU&#x5206;&#x6570;&#xFF0C;&#x4F46;&#x662F;&#x5F97;&#x5206;&#x76F8;&#x5F53;&#x63A5;&#x8FD1;&#x3002;&#x4F46;&#x8FD9;&#x4E9B;&#x5F97;&#x5206;&#x7A76;&#x7ADF;&#x610F;&#x5473;&#x7740;&#x4EC0;&#x4E48;&#x5462;&#xFF1F;&#x4E3A;&#x4E86;&#x7814;&#x7A76;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5B9A;&#x6027;&#x5730;&#x68C0;&#x67E5;&#x6A21;&#x578B;&#x3002;</p>
<p><img src="img/d4bdc63406e2c1068c0b8f5935863ac7.jpg" alt="test" title="&#x8868;8 - 1&#x3002;&#x5148;&#x524D;&#x663E;&#x793A;&#x7684;&#x4E24;&#x4E2A;&#x6A21;&#x578B;&#x7684;BLEU&#x5F97;&#x5206;;BLEU&#x88AB;&#x8BA1;&#x7B97;&#x4E3A;1-&#x3001;2-&#x3001;3-&#x548C;4&#x514B;&#x91CD;&#x53E0;&#x7684;&#x7B80;&#x5355;&#x5E73;&#x5747;&#x503C;"></p>
<p>&#x5BF9;&#x4E8E;&#x6211;&#x4EEC;&#x66F4;&#x6DF1;&#x5165;&#x7684;&#x68C0;&#x67E5;&#xFF0C;&#x6211;&#x4EEC;&#x7ED8;&#x5236;&#x6CE8;&#x610F;&#x529B;&#x5206;&#x6570;&#xFF0C;&#x4EE5;&#x67E5;&#x770B;&#x5B83;&#x4EEC;&#x662F;&#x5426;&#x5728;&#x6E90;&#x53E5;&#x548C;&#x76EE;&#x6807;&#x53E5;&#x4E4B;&#x95F4;&#x63D0;&#x4F9B;&#x4EFB;&#x4F55;&#x7C7B;&#x578B;&#x7684;&#x5BF9;&#x9F50;&#x4FE1;&#x606F;&#x3002;&#x6211;&#x4EEC;&#x53D1;&#x73B0;&#x5728;&#x8FD9;&#x6B21;&#x68C0;&#x67E5;&#x4E2D;&#x4E24;&#x4E2A;&#x6A21;&#x578B;&#x4E4B;&#x95F4;&#x5F62;&#x6210;&#x4E86;&#x9C9C;&#x660E;&#x7684;&#x5BF9;&#x6BD4;.&#x56FE;8-12&#x663E;&#x793A;&#x4E86;&#x5177;&#x6709;&#x9884;&#x5B9A;&#x91C7;&#x6837;&#x7684;&#x6A21;&#x578B;&#x7684;&#x6BCF;&#x4E2A;&#x89E3;&#x7801;&#x5668;&#x65F6;&#x95F4;&#x6B65;&#x957F;&#x7684;&#x6CE8;&#x610F;&#x6982;&#x7387;&#x5206;&#x5E03;&#x3002;&#x5728;&#x8BE5;&#x6A21;&#x578B;&#x4E2D;&#xFF0C;&#x6CE8;&#x610F;&#x6743;&#x91CD;&#x5BF9;&#x4E8E;&#x4ECE;&#x6570;&#x636E;&#x96C6;&#x7684;&#x9A8C;&#x8BC1;&#x90E8;&#x5206;&#x91C7;&#x6837;&#x7684;&#x53E5;&#x5B50;&#x6392;&#x5217;&#x5F97;&#x76F8;&#x5F53;&#x597D;&#x3002;</p>
<p><img src="img/8ceee1f109cfad6089fa1ae474c8725c.jpg" alt="test1" title="&#x56FE;8-12\. &#x5177;&#x6709;&#x9884;&#x5B9A;&#x91C7;&#x6837;&#x7684;&#x6A21;&#x578B;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x6743;&#x91CD;&#x77E9;&#x9635;&#x88AB;&#x7ED8;&#x5236;&#x4E3A;&#x6A21;&#x578B;&#x6027;&#x80FD;&#x7684;&#x5B9A;&#x6027;&#x8BC4;&#x4F30;"></p>
<h2 id="summary">Summary</h2>
<p>&#x672C;&#x7AE0;&#x91CD;&#x70B9;&#x4ECB;&#x7ECD;&#x4E86;&#x5728;&#x6240;&#x8C13;&#x7684;&#x6761;&#x4EF6;&#x751F;&#x6210;&#x6A21;&#x578B;&#x7684;&#x6761;&#x4EF6;&#x4E0A;&#x4E0B;&#x6587;&#x4E2D;&#x751F;&#x6210;&#x5E8F;&#x5217;&#x8F93;&#x51FA;&#x3002;&#x5F53;&#x6761;&#x4EF6;&#x4E0A;&#x4E0B;&#x6587;&#x672C;&#x8EAB;&#x6765;&#x81EA;&#x53E6;&#x4E00;&#x4E2A;&#x5E8F;&#x5217;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x5176;&#x79F0;&#x4E3A;&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;&#x6216;S2S&#x6A21;&#x578B;&#x3002;&#x6211;&#x4EEC;&#x8FD8;&#x8BA8;&#x8BBA;&#x4E86;S2S&#x6A21;&#x578B;&#x5982;&#x4F55;&#x6210;&#x4E3A;&#x7F16;&#x7801;&#x5668; - &#x89E3;&#x7801;&#x5668;&#x6A21;&#x578B;&#x7684;&#x7279;&#x4F8B;&#x3002;&#x4E3A;&#x4E86;&#x5145;&#x5206;&#x5229;&#x7528;&#x5E8F;&#x5217;&#xFF0C;&#x6211;&#x4EEC;&#x8BA8;&#x8BBA;&#x4E86;&#x7B2C;6&#x7AE0;&#x548C;&#x7B2C;7&#x7AE0;&#x4E2D;&#x8BA8;&#x8BBA;&#x7684;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#x7684;&#x7ED3;&#x6784;&#x53D8;&#x4F53;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x53CC;&#x5411;&#x6A21;&#x578B;&#x3002;&#x6211;&#x4EEC;&#x8FD8;&#x5B66;&#x4E60;&#x4E86;&#x5982;&#x4F55;&#x7ED3;&#x5408;&#x6CE8;&#x610F;&#x673A;&#x5236;&#x6765;&#x6709;&#x6548;&#x6355;&#x83B7;&#x66F4;&#x957F;&#x8DDD;&#x79BB;&#x7684;&#x80CC;&#x666F;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x6211;&#x4EEC;&#x8BA8;&#x8BBA;&#x4E86;&#x5982;&#x4F55;&#x8BC4;&#x4F30;&#x5E8F;&#x5217;&#x5230;&#x5E8F;&#x5217;&#x6A21;&#x578B;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;&#x7AEF;&#x5230;&#x7AEF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#x793A;&#x4F8B;&#x8FDB;&#x884C;&#x6F14;&#x793A;&#x3002;&#x5230;&#x76EE;&#x524D;&#x4E3A;&#x6B62;&#xFF0C;&#x6211;&#x4EEC;&#x5DF2;&#x5C06;&#x672C;&#x4E66;&#x7684;&#x6BCF;&#x4E00;&#x7AE0;&#x4E13;&#x95E8;&#x7528;&#x4E8E;&#x7279;&#x5B9A;&#x7684;&#x7F51;&#x7EDC;&#x67B6;&#x6784;&#x3002;&#x5728;&#x4E0B;&#x4E00;&#x7AE0;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x524D;&#x9762;&#x7684;&#x6240;&#x6709;&#x7AE0;&#x8282;&#x7ED3;&#x5408;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x5E76;&#x67E5;&#x770B;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x5404;&#x79CD;&#x6A21;&#x578B;&#x4F53;&#x7CFB;&#x7ED3;&#x6784;&#x7684;&#x7EFC;&#x5408;&#x6784;&#x5EFA;&#x8BB8;&#x591A;&#x771F;&#x5B9E;&#x7CFB;&#x7EDF;&#x7684;&#x793A;&#x4F8B;&#x3002;</p>
<h2 id="references">References</h2>
<ol>
<li><p>Yoshua Bengio, Patrice Simard, and Paolo Frasconi. (1994). &#x201C;Learning long-term dependencies with gradient descent is difficult.&#x201D; IEEE transactions on neural networks.</p>
</li>
<li><p>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. (2002) &#x201C;BLEU: a method for automatic evaluation of machine translation.&#x201D; In Proceedings ACL.. Hal Daum&#xE9; III, John Langford, Daniel Marcu. (2009). &#x201C;Search-based Structured Prediction.&#x201D; In Machine Learning Journal.</p>
</li>
<li><p>Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer. &#x201C;Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks.&#x201D; In Proceedings of NIPS 2015.</p>
</li>
<li><p>Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. (2015). &#x201C;Effective Approaches to Attention-based Neural Machine Translation.&#x201D; In Proceedings of EMNLP.</p>
</li>
<li><p>Phong Le and Willem Zuidema. (2016). &#x201C;Quantifying the Vanishing Gradient and Long Distance Dependency Problem in Recursive Neural Networks and Recursive LSTMs.&#x201D; Proceedings of the 1st Workshop on Representation Learning for NLP.</p>
</li>
<li><p>Philipp Koehn, Rebecca Knowles. (2017). &#x201C;Six Challenges for Neural Machine Translation.&#x201D; In Proceedings of the First Workshop on Neural Machine Translation.</p>
</li>
<li><p>Graham Neubig. (2017). &#x201C;Neural Machine Translation and Sequence-to-Sequence Models: A Tutorial.&#x201D; arXiv:1703.01619.</p>
</li>
<li><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, &#x141;ukasz Kaiser, and Illia Polosukhin. (2017). &#x201C;Attention is all you need.&#x201D; In Proceedings of NIPS.</p>
</li>
</ol>
<p>In this chapter, we reserve the symbol &#x3D5; for encodings. This is not possible for streaming applications, but a large number of practical applications of NLP happen in a batch (non-streaming) context anyways. Sentences like the one in this example are called &#x201C;Garden Path Sentences.&#x201D; Such sentences are more common than one would imagine, for e.g., newspaper headlines use such constructs regularly. See <a href="https://en.wikipedia.org/wiki/Garden_path_sentence" target="_blank">https://en.wikipedia.org/wiki/Garden_path_sentence</a>. Consider the two meanings of &#x201C;duck&#x201D; (i) &#x25A1; (noun, quack quack) and (ii) evade (verb) The terminology key, values, and query can be quite confusing for the beginner, but we introduce them here anyway because they have now become a standard. It is worth reading this section (8.3.1) a few times until these concepts become clear. The &#x201C;Key, Value, Query&#x201D; terminology comes in because the attention was initially thought of as a search task. For an extended review of these concepts and attention in general, visit <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a>. So much that the original 2002 paper that proposed that BLEU received a &#x201C;test of the time award&#x201D; in 2018. For an example, see <a href="https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py" target="_blank">https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py</a>. SacreBLEU is the standard when it comes to machine translation evaluation. The dataset was retrieved from <a href="http://www.manythings.org/anki/" target="_blank">http://www.manythings.org/anki/</a>. We also include the cases in which these subject-verb pairs are contractions, such as &#x201C;I&#x2019;m&#x201D;, &#x201C;we&#x2019;re&#x201D;, and &#x201C;he&#x2019;s&#x201D;. This simply means that the model will be able to see the entire dataset 10 times faster. It doesn&#x2019;t exactly follow that the convergence will happen in one-tenth the time, because it could be that the model needs to see this dataset for a smaller number of epochs, or some other confounding factor. Sorting the sequences in order takes advantage of a low-level CUDA primitive for RNNs. You should try to convince yourself of this by either visualizing the computations or drawing them out. As a hint, consider the single recurrent step: the input and last hidden are weighted and added together with the bias. If the input is all 0&#x2019;s, what effect does the bias have on the output? We utilize the describe function shown in section 1.4. Starting from left to right on the sequence dimension, any position past the known length of the sequence is assumed to be masked. The Vectorizer prepends the BEGIN-OF-SEQUENCE token to the sequence, so the first observation is always a special token indicating the boundary. See section 7.3 of Graham Neubig&#x2019;s tutorial for a discussion on connecting encoders and decoders in neural machine translation. See (Neubig, 2017). We refer you to Luong, Pham, and Manning (2011), in which they outline three different scoring functions. Each batch item is a sequence and the probabilities for each sequence sum to 1. Broadcasting happens when a tensor has a dimension of size 1. Let this tensor be called Tensor A. When Tensor A is used in an element-wise mathematical operation (such as addition or subtraction) with another tensor called Tensor B, its shape (the number of elements on each dimension) should be identical except for the dimension with size 1. The operation of Tensor A on Tensor B is repeated for each position in Tensor B. If Tensor A has a shape (10, 1, 10) and Tensor B has a shape (10, 5, 10), A+B will repeat the addition of Tensor A for each of the five positions in Tensor B. We refer you to two papers on this topic: &#x201C;Search-based Structured Prediction&#x201D; by Daum&#xE9;, Langford, Marcu, and &#x201C;Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks&#x201D; by Bengio, Vinyals, Jaitly, Shazeer (2015). If you&#x2019;re familiar with Monte Carlo sampling for optimization techniques such as Markov Chain Monte Carlo, you will recognize this pattern. Primarily, this is because gradient descent and automatic differentiation is an elegant abstraction between model definitions and their optimization. <a href="https://github.com/joosthub/nlpbook/chapters/chapter_8/example_8_5" target="_blank">https://github.com/joosthub/nlpbook/chapters/chapter_8/example_8_5</a> We omit a plot for the first model because it attended to only the final state in the encoder RNN. As noted by Koehn and Knowles (2017), the attention weights are endemic of many different situations. We suspect the attention weights in the first model did not need to rely on attention as much because the information it needed was already encoded in the states of the encoder GRU.</p>
<p><hr></p>
<div align="center">
    <p><a href="http://www.apachecn.org" target="_blank"><font face="KaiTi" size="6" color="red">&#x6211;&#x4EEC;&#x4E00;&#x76F4;&#x5728;&#x52AA;&#x529B;</font></a></p>
    <p><a href="https://github.com/apachecn/nlp-pytorch-zh/" target="_blank">apachecn/nlp-pytorch-zh</a></p>
    <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=nlp-pytorch-zh&amp;type=watch&amp;count=true&amp;v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=nlp-pytorch-zh&amp;type=star&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=nlp-pytorch-zh&amp;type=fork&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <a target="_blank" href="../shang.qq.com/wpa/qunwpa"><img border="0" src="http://data.apachecn.org/img/logo/ApacheCN-group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
</div>
 <div style="text-align:center;margin:0 0 10.5px;">
     <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
     <ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-3565452474788507" data-ad-slot="2543897000">
     </ins>
     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>

    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

</div>

<p><meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"></p>
<p><iframe src="https://www.bilibili.com/read/cv2710377" style="display:none"></iframe>
<img src="http://t.cn/AiCoDHwb" hidden="hidden"></p>
<div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
    <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
        clientID: '1eba1fde838d39ce2ba9',
        clientSecret: '0bdf321e160ca29b2d54e8722700dd5accb084e0',
        repo: 'nlp-pytorch-zh',
        owner: 'apachecn',
        admin: ['jiangzhonglian', 'wizardforcel'],
        id: md5(location.pathname),
        distractionFreeMode: false
        })
        gitalk.render('gitalk-container')
    </script>
</div>

<footer class="page-footer"><span class="copyright">Copyright &#xA9; ibooker.org.cn 2019 all right reserved&#xFF0C;&#x7531; ApacheCN &#x56E2;&#x961F;&#x63D0;&#x4F9B;&#x652F;&#x6301;</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A; 
2019-07-29 11:38:33
</span></footer>
<script>console.log("plugin-popup....");document.onclick = function(e){ e.target.tagName === "IMG" && window.open(e.target.src,e.target.src)}</script><style>img{cursor:pointer}</style>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="7.html" class="navigation navigation-prev " aria-label="Previous page: Chapter 7.自然语言处理的中间 Sequence Modeling">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="9.html" class="navigation navigation-next " aria-label="Next page: Chapter 9.经典, 前沿和后续步骤">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Chapter 8.用于自然语言处理的高级 Sequence","level":"1.9","depth":1,"next":{"title":"Chapter 9.经典, 前沿和后续步骤","level":"1.10","depth":1,"path":"docs/9.md","ref":"docs/9.md","articles":[]},"previous":{"title":"Chapter 7.自然语言处理的中间 Sequence Modeling","level":"1.8","depth":1,"path":"docs/7.md","ref":"docs/7.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","github-buttons","-sharing","insert-logo","sharing-plus","back-to-top-button","code","copy-code-button","mathjax","pageview-count","edit-link","emphasize","alerts","auto-scroll-table","popup","hide-element","page-toc-button","tbfed-pagefooter","sitemap","advanced-emoji","expandable-chapters","splitter","search-pro"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"},"emphasize":{},"github":{"url":"https://github.com/apachecn/nlp-pytorch-zh"},"splitter":{},"search-pro":{},"search":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"auto-scroll-table":{},"popup":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sitemap":{"hostname":"https://nlp-pt.apachecn.org"},"page-toc-button":{"maxTocDepth":4,"minTocSize":4},"back-to-top-button":{},"pageview-count":{},"alerts":{},"github-buttons":{"buttons":[{"user":"apachecn","repo":"nlp-pytorch-zh","type":"star","count":true,"size":"small"}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"copy-code-button":{},"advanced-emoji":{"embedEmojis":false},"sharing":{"qq":false,"all":["qq","douban","facebook","google","linkedin","twitter","weibo","whatsapp"],"douban":false,"facebook":false,"weibo":true,"whatsapp":false,"twitter":false,"line":false,"google":false,"qzone":true},"edit-link":{"label":"编辑本页","base":"https://github.com/apachecn/nlp-pytorch-zh/blob/master"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 150px; min-height: 150px","url":"https://nlp-pt.apachecn.org/cover.jpg"},"expandable-chapters":{}},"theme":"default","author":"ApacheCN","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"NLP with PyTorch 中文文档","language":"zh-hans","gitbook":"*","description":"NLP with PyTorch 中文文档"},"file":{"path":"docs/8.md","mtime":"2019-07-29T03:38:33.970Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-05-09T15:06:48.544Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-alerts/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-auto-scroll-table/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

